{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c28feff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reasons, file descriptors (FDs) do not get released.\n",
    "# This is a work around which increases the allowed limit.\n",
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (65535, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eadc2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmedmohammed/opt/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.integrate import simpson\n",
    "import torch\n",
    "import torch_scatter\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from copy import deepcopy\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c53ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "train_B = 16\n",
    "val_B = 1\n",
    "\n",
    "p_dropout = 0.\n",
    "\n",
    "SCALE = True\n",
    "data_folder = 'BH average 100-sps (0.75-38 Hz)'\n",
    "files_names = os.listdir(data_folder)\n",
    "\n",
    "USE_SURROGATES = False\n",
    "no_surrogates = 500\n",
    "surrogate_thr = 0.9\n",
    "fs = 100\n",
    "nperseg = 140\n",
    "noverlap = 135\n",
    "freq_bands = ['delta', 'theta', 'alpha', 'beta']\n",
    "\n",
    "attention = True\n",
    "dedicated_vgg = False\n",
    "eps = 0.\n",
    "train_eps = False\n",
    "dedicated_GIN = True\n",
    "\n",
    "montage = 'BH'\n",
    "if montage == 'BH':\n",
    "    montage = ['Fp1','F7','T3','T5','O1','F3','C3','P3','Fz','Cz','Pz','Fp2','F8','T4','T6','O2','F4','C4','P4']\n",
    "elif montage == 'MCH':\n",
    "    montage = ['C3','C4','O1','O2','Cz','F3','F4','F7','F8','Fz','Fp1','Fp2','P3','P4','Pz','T3','T4','T5','T6']\n",
    "else:\n",
    "    raise NameError('Unavailable Montage')\n",
    "\n",
    "\n",
    "g1 = ['PAT31', 'MC', 'FEsg', 'DHut', 'NKra', 'PAT2']\n",
    "g2 = ['RC', 'MBra', 'ESow', 'PAT1', 'EG', 'FigSa', 'PAT28']\n",
    "g3 = ['PAT47', 'RA', 'PAT51', 'MPi', 'GNA', 'LM', 'DG']\n",
    "g4 = ['PAT33', 'PB', 'PAT22', 'MAXJ', 'PAT19', 'LP', 'HeMod', 'PAT50', 'PJuly']\n",
    "g5 = ['PAT48', 'KS', 'PAT3', 'PAT8', 'LRio', 'HB', 'ALo', 'JAlv', 'PAT25', 'AR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e8d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patients = g1 + g3 + g4 + g5\n",
    "val_patients = g2\n",
    "del g1, g2, g3, g4, g5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e9efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpli_raw(x, y, fs, nperseg, noverlap, norm='ortho'):\n",
    "    # x.shape = y.shape: (no_time_samples,) OR (no_signals, no_time_samples)\n",
    "    # If x and y are 2-D, the wpli is computed for each pair (x_i, y_i)\n",
    "    # Returns:\n",
    "    # 1) f: (no_positive_freqs,)\n",
    "    # 2) wpli: (no_positive_freqs,) OR (no_signals, no_positive_freqs) depending on x and y (1-D OR 2-D)\n",
    "    \n",
    "    no_original_dimensions = x.ndim\n",
    "    \n",
    "    if (x.shape != y.shape) or (no_original_dimensions not in {1, 2}):\n",
    "        raise NameError(\n",
    "            f'x & y MUST be 1/2-D arrays of the same shape. Given x.shape: ({x.shape}), y.shape: ({y.shape})!'\n",
    "        )\n",
    "    \n",
    "    if no_original_dimensions == 1:\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        y = np.expand_dims(y, axis=0)\n",
    "    \n",
    "    # Now, x.shape = y.shape: (no_signals, no_time_samples)\n",
    "    no_signals, no_time_samples = x.shape\n",
    "    step = nperseg - noverlap\n",
    "    start_time_idx_last_segment = no_time_samples - nperseg\n",
    "    \n",
    "    \n",
    "    if ((start_time_idx_last_segment % step) != 0):\n",
    "        raise NameError('nperseg & noverlap should be chosen carefully!')\n",
    "    \n",
    "    no_segments = 1 + (start_time_idx_last_segment // step)\n",
    "    \n",
    "    \n",
    "    X = np.zeros((no_signals, no_segments, nperseg))\n",
    "    Y = np.zeros((no_signals, no_segments, nperseg))\n",
    "    \n",
    "    \n",
    "    start_time_idx = 0\n",
    "    for segment_idx in range(no_segments):\n",
    "        end_time_idx = start_time_idx + nperseg\n",
    "        X[:, segment_idx, :] = x[:, start_time_idx : end_time_idx]\n",
    "        Y[:, segment_idx, :] = y[:, start_time_idx : end_time_idx]\n",
    "        start_time_idx += step\n",
    "    \n",
    "    \n",
    "    f = np.arange(start=0, stop=1+(nperseg//2), step=1) * (fs / nperseg)     # (no_positive_freqs,)\n",
    "    \n",
    "    X = np.fft.rfft(X, norm=norm)     # (no_signals, no_segments, no_positive_freqs)\n",
    "    Y = np.fft.rfft(Y, norm=norm)     # (no_signals, no_segments, no_positive_freqs)\n",
    "    \n",
    "    I = X * Y.conjugate()\n",
    "    I = I.imag\n",
    "    \n",
    "    numerator = np.abs(np.mean(I, axis=-2, keepdims=False))     # (no_signals, no_positive_freqs)\n",
    "    denominator = np.mean(np.abs(I), axis=-2, keepdims=False)     # (no_signals, no_positive_freqs)\n",
    "    \n",
    "    mask = (denominator == 0)\n",
    "    denominator[mask] = np.inf\n",
    "    \n",
    "    wpli = (numerator / denominator)     # (no_signals, no_positive_freqs)\n",
    "    \n",
    "    if no_original_dimensions == 1:\n",
    "        x = x.squeeze(axis=0)           # (no_time_samples,)\n",
    "        y = y.squeeze(axis=0)           # (no_time_samples,)\n",
    "        wpli = wpli.squeeze(axis=0)     # (no_positive_freqs,)\n",
    "    \n",
    "    return f, wpli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bef6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_FC_integral(f, freq_FC, freq_bands=['delta', 'theta', 'alpha', 'beta']):\n",
    "    # f: (no_positive_freqs,)\n",
    "    # freq_FC: (no_positive_freqs,) OR (no_signals, no_positive_freqs)\n",
    "    # Returns:\n",
    "    # The integrated connectivity across the specified frequency bands. The i/p, o/p shapes are as follows:\n",
    "    # freq_FC: (no_positive_freqs,) ====Returns====> (num_freq_bands,)\n",
    "    # OR\n",
    "    # freq_FC: (no_signals, no_positive_freqs) ====Returns====> (no_signals, num_freq_bands)\n",
    "    # Note: num_freq_bands = len(freq_bands)\n",
    "    \n",
    "    num_freq_bands = len(freq_bands)\n",
    "    no_original_dimensions_freq_FC = freq_FC.ndim\n",
    "    \n",
    "    if f.ndim != 1:\n",
    "        raise NameError('f should be a 1-D array!')\n",
    "    elif len(f) != freq_FC.shape[-1]:\n",
    "        raise NameError(f'len(f) ({len(f)}) != freq_FC.shape[-1] ({freq_FC.shape[-1]}) ... They have to match !!')\n",
    "    elif no_original_dimensions_freq_FC == 1:\n",
    "        freq_FC = np.expand_dims(freq_FC, axis=0)\n",
    "    elif no_original_dimensions_freq_FC != 2:\n",
    "        raise NameError('freq_FC should be 1/2-D array!')\n",
    "    \n",
    "    \n",
    "    # Now, freq_FC: (no_signals, no_positive_freqs)\n",
    "    no_signals, _ = freq_FC.shape\n",
    "    \n",
    "    ans = np.zeros((no_signals, num_freq_bands))\n",
    "    \n",
    "    df = f[1] - f[0]\n",
    "    for freq_band_idx, freq_band in enumerate(freq_bands):\n",
    "        if freq_band == 'delta':\n",
    "            low, high = 0.5, 4.\n",
    "        elif freq_band == 'theta':\n",
    "            low, high = 4., 8.\n",
    "        elif freq_band == 'alpha':\n",
    "            low, high = 8., 13.\n",
    "        elif freq_band == 'beta':\n",
    "            low, high = 13., 30.\n",
    "        elif freq_band == 'wide':\n",
    "            low, high = 0.5, 30.\n",
    "        else:\n",
    "            raise NameError('Unavailable Band')\n",
    "        \n",
    "        \n",
    "        mask = np.logical_and(low <= f, f <= high)\n",
    "        masked_f = f[mask]\n",
    "        \n",
    "        mask = np.broadcast_to(mask, (no_signals, len(mask)))\n",
    "        masked_freq_FC = freq_FC[mask].reshape((no_signals, len(masked_f)))\n",
    "        \n",
    "        \n",
    "        f_L = masked_f[0]\n",
    "        f_U = masked_f[-1]\n",
    "        \n",
    "        ans[:, freq_band_idx] = simpson(masked_freq_FC, dx=df) / (f_U - f_L)\n",
    "    \n",
    "    \n",
    "    if no_original_dimensions_freq_FC == 1:\n",
    "        freq_FC = freq_FC.squeeze(axis=0)     # (no_positive_freqs,)\n",
    "        ans = ans.squeeze(axis=0)       # (num_freq_bands,)\n",
    "    \n",
    "    return ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a36ab8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpli_combined(x, y, fs, nperseg, noverlap, freq_bands=['delta', 'theta', 'alpha', 'beta']):\n",
    "    # x.shape = y.shape: (no_time_samples,) OR (no_signals, no_time_samples)\n",
    "    # Returns: \n",
    "    # (num_freq_bands,) OR (no_signals, num_freq_bands) depending on x and y (1-D OR 2-D)\n",
    "    \n",
    "    f, wpli = wpli_raw(x, y, fs, nperseg, noverlap)\n",
    "    ans = freq_FC_integral(f, wpli, freq_bands=freq_bands)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3f3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wpli_matrix_generator(segment, fs, nperseg, noverlap, freq_bands=['delta', 'theta', 'alpha', 'beta']):\n",
    "    # segment: (no_electrodes/no_signals, no_time_samples)\n",
    "    # fs: sampling rate\n",
    "    # Returns:\n",
    "    # wpli_matrix: (no_connectivities, num_freq_bands) ==> Each row represents FC_{x,y}^B for all B in freq_bands\n",
    "    \n",
    "    no_electrodes, no_time_samples = segment.shape\n",
    "    \n",
    "    wpli_list = []\n",
    "    for x_idx in range(no_electrodes - 1):\n",
    "        x_signal = segment[x_idx]\n",
    "        x = np.broadcast_to(x_signal, (no_electrodes - x_idx - 1, no_time_samples))\n",
    "        y = segment[x_idx + 1 : , :]\n",
    "        x_connectivity = wpli_combined(x, y, fs, nperseg, noverlap, freq_bands=freq_bands)\n",
    "        wpli_list.append(x_connectivity)\n",
    "    \n",
    "    \n",
    "    wpli_matrix = np.concatenate(wpli_list)     # (no_connectivities, num_freq_bands)\n",
    "    \n",
    "    return wpli_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a2ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogate_func(x, no_surrogates, seed=None, norm='ortho'):\n",
    "    # x: (no_time_samples,) ====Returns====> (no_surrogates, no_time_samples)\n",
    "    # OR\n",
    "    # x: (no_signals, no_time_samples) ====Returns====> (no_signals, no_surrogates, no_time_samples)\n",
    "    no_original_dimensions = x.ndim\n",
    "    \n",
    "    if no_original_dimensions == 1:\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    elif no_original_dimensions != 2:\n",
    "        raise NameError(f'x MUST be 1/2-D array. Given x.shape: ({x.shape}) !')\n",
    "    \n",
    "    # Now, x.shape: (no_signals, no_time_samples)\n",
    "    no_signals, no_time_samples = x.shape\n",
    "    surrogates = np.zeros((no_signals, no_surrogates, no_time_samples))\n",
    "    \n",
    "    X = np.fft.rfft(x, norm=norm)          # (no_signals, no_positive_freqs)\n",
    "    X_abs = np.abs(X)                          # (no_signals, no_positive_freqs)\n",
    "    X_angle = np.angle(X)                      # (no_signals, no_positive_freqs)\n",
    "    \n",
    "    if seed:\n",
    "        rng = np.random.default_rng(seed)\n",
    "    else:\n",
    "        rng = np.random.default_rng()\n",
    "    \n",
    "    for surrogate_idx in range(no_surrogates):\n",
    "        rng.permuted(X_angle, axis=-1, out=X_angle)\n",
    "        S = X_abs * np.exp(1.0j * X_angle)     # (no_signals, no_positive_freqs)\n",
    "        surrogates[:, surrogate_idx, :] = np.fft.irfft(S, n=no_time_samples, norm=norm)\n",
    "    \n",
    "    \n",
    "    if no_original_dimensions == 1:\n",
    "        x = x.squeeze(axis=0)                       # (no_time_samples,)\n",
    "        surrogates = surrogates.squeeze(axis=0)     # (no_surrogates, no_time_samples)\n",
    "    \n",
    "    return surrogates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a578fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_func(freq_FC_matrix, USE_SURROGATES, segment, no_surrogates=500, freq_FC_method='wpli', surrogate_thr=0.90, freq_bands=['delta','theta','alpha','beta'], min_thr=0.75, quantile=0.75):\n",
    "    # Note: E is the number of electrodes (no_electrodes)\n",
    "    \n",
    "    # freq_FC_matrix: (no_connectivities, num_freq_bands)\n",
    "    # 1st row represents FC between electrode 0 and electrode 1, i.e., FC(0, 1)\n",
    "    # 2nd row represents FC(0, 2)\n",
    "    # 3rd row represents FC(0, 3)\n",
    "    # ....\n",
    "    # (E - 1)th row represents FC(0, E - 1)\n",
    "    # (E)th row represents FC(1, 2)\n",
    "    # (E + 1)th row represents FC(1, 3)\n",
    "    # ....\n",
    "    # last row row represents FC(E - 2, E - 1)\n",
    "    \n",
    "    # USE_SURROGATES: Boolean to determine using surrogates in thresholding or not\n",
    "    # segment: (no_electrodes/no_signals, no_time_samples)\n",
    "    # freq_FC_method: The frequency functional connectivity method to use among the surrogates\n",
    "    # Note: {segment,no_surrogates,freq_FC_method,surrogate_thr,freq_bands} are only used if USE_SURROGATES=True\n",
    "    \n",
    "    # Returns:\n",
    "    # A list of 1-D arrays (each array corresponds to one of the frequency bands). Each 1-D array\n",
    "    # includes the numerical indices of the True connection as explained above in \"freq_FC_matrix\"\n",
    "    \n",
    "    \n",
    "    no_connectivities, num_freq_bands = freq_FC_matrix.shape\n",
    "    \n",
    "    thr_1 = np.quantile(freq_FC_matrix, quantile, axis=0)               # (num_freq_bands,)\n",
    "    thr_2 = np.array([min_thr for _ in range(num_freq_bands)])     # (num_freq_bands,)\n",
    "    thr = np.maximum(thr_1, thr_2)                                 # (num_freq_bands,)\n",
    "    thr = np.broadcast_to(thr, (no_connectivities, num_freq_bands))\n",
    "    masked_freq_FC_matrix = (freq_FC_matrix >= thr)                # (no_connectivities, num_freq_bands)\n",
    "    \n",
    "    \n",
    "    if USE_SURROGATES:\n",
    "        # Some True elements in masked_freq_FC_matrix may be converted to False\n",
    "        # if they fail to pass the given surrogate_thr\n",
    "        no_electrodes = segment.shape[0]\n",
    "        \n",
    "        masked_any = np.any(masked_freq_FC_matrix, axis=-1)\n",
    "        index = np.argwhere(masked_any).squeeze(axis=1)\n",
    "        min_electrode, max_electrode = index_to_min_max_electrodes(index, no_electrodes)\n",
    "        \n",
    "        selected_electrodes = np.concatenate((min_electrode, max_electrode))\n",
    "        selected_electrodes = np.unique(selected_electrodes).tolist()\n",
    "        electrode_num_to_surrogate_idx = {e_num: s_idx for s_idx, e_num in enumerate(selected_electrodes)}\n",
    "        \n",
    "        surrogates = surrogate_func(segment[selected_electrodes], no_surrogates)\n",
    "        \n",
    "        for idx, min_elec, max_elec in zip(index, min_electrode, max_electrode):\n",
    "            idx, min_elec, max_elec = idx.item(), min_elec.item(), max_elec.item()\n",
    "            \n",
    "            x = surrogates[electrode_num_to_surrogate_idx[min_elec]]\n",
    "            y = surrogates[electrode_num_to_surrogate_idx[max_elec]]\n",
    "            \n",
    "            bands_idxs = np.argwhere(masked_freq_FC_matrix[idx]).squeeze(axis=1)\n",
    "            bands_names = [freq_bands[band_idx.item()] for band_idx in bands_idxs]\n",
    "            \n",
    "            if freq_FC_method == 'wpli':\n",
    "                surrogates_FC = wpli_combined(x, y, fs, nperseg, noverlap, freq_bands=bands_names)\n",
    "            else:\n",
    "                raise NameError('The only defined frequency based functional connectivity is wpli!')\n",
    "            \n",
    "            TP = (surrogates_FC < freq_FC_matrix[idx, bands_idxs])\n",
    "            TP = TP.mean(axis=0)\n",
    "            \n",
    "            set_to_false_bands_idxs = bands_idxs[TP < surrogate_thr]\n",
    "            masked_freq_FC_matrix[idx, set_to_false_bands_idxs] = False\n",
    "    \n",
    "    \n",
    "    lis = []\n",
    "    for band_idx in range(num_freq_bands):\n",
    "        masked_freq_FC_vector_band = masked_freq_FC_matrix[:, band_idx]\n",
    "        index = np.argwhere(masked_freq_FC_vector_band).squeeze(axis=1)\n",
    "        lis.append(index)\n",
    "    \n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59e71925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_min_max_electrodes(index, E):\n",
    "    # IMPORTANT ASSUMPTION: wpli(x,y) = wpli(y,x) which is valid for wpli method. This code will NOT work\n",
    "    # for unsummetric connectivity methods\n",
    "    \n",
    "    # numbers in index represent the following:\n",
    "    # 0 ===> (electrode 0, electrode 1)\n",
    "    # 1 ===> (0, 2)\n",
    "    # 2 ===> (0, 3)\n",
    "    # ....\n",
    "    # E - 2 ===> (0, E - 1)\n",
    "    # E - 1 ===> (1, 2)\n",
    "    # E ===> (1, 3)\n",
    "    # ....\n",
    "    # greatest number ===> (E - 2, E - 1)\n",
    "    \n",
    "    # Example: E = 19\n",
    "    #             a = [18, 18+17=35, 18+17+16=51, 18+17+16+15=66, ......, 18+17+16+15+14+...+1]\n",
    "    # min_electrode =   0,        1,           2,              3, ......,                E - 2\n",
    "    \n",
    "    \n",
    "    B = 3 - (2 * E)\n",
    "    C = 2 * (index + 1 - E)\n",
    "    sqrt_term = (B ** 2) - (4 * C)\n",
    "    min_electrode = (-B - np.sqrt(sqrt_term)) / 2\n",
    "    min_electrode = np.floor(1 + min_electrode).astype('int')\n",
    "    i = min_electrode - 1\n",
    "    a_i = (i + 1) * (E - 1 - (i / 2))\n",
    "    max_electrode = min_electrode + 1 + (index - a_i.astype('int'))\n",
    "    \n",
    "    return min_electrode, max_electrode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39fad633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacencies_converter(index, montage):\n",
    "    # Converts index which is a 1-D numpy array (representing an adjacency by\n",
    "    # indices) into TWO output torch tensors (each 1-D), namely, src and dst.\n",
    "    # src[i] ---> dst[i]: is an existing link in the graph.\n",
    "    # src and dst include the indexes of the electrodes as specified by the montage list.\n",
    "    \n",
    "    # Additionally, we add (j, i) for each existing (i, j)\n",
    "    \n",
    "    # index: 1-D numpy array.\n",
    "    # montage: order of the electrodes\n",
    "    \n",
    "    # Returns:\n",
    "    # list of 2 tensors (each 1-D and possibly empty), src and dst\n",
    "    \n",
    "    # Skip the checks for valid input!\n",
    "    \n",
    "    src = []\n",
    "    dst = []\n",
    "    E = len(montage)\n",
    "    min_electrode, max_electrode = index_to_min_max_electrodes(index, E)\n",
    "    \n",
    "    for min_elec, max_elec in zip(min_electrode, max_electrode):\n",
    "        min_elec, max_elec = min_elec.item(), max_elec.item()\n",
    "        src += [min_elec, max_elec]\n",
    "        dst += [max_elec, min_elec]\n",
    "\n",
    "    \n",
    "    src = torch.tensor(src, dtype=torch.long)\n",
    "    dst = torch.tensor(dst, dtype=torch.long)\n",
    "    \n",
    "    return [src, dst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e72d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_patient_data(patient_name):\n",
    "    # no_electrodes: E\n",
    "    patient_segments = []\n",
    "    patient_adjs = []\n",
    "    patient_labels = []\n",
    "    \n",
    "    regex = re.compile(f'{patient_name}\\D[0-9.a-z_A-Z]*')\n",
    "    \n",
    "    \n",
    "    for file_name in files_names:\n",
    "        if regex.match(file_name):\n",
    "            # set label\n",
    "            if 'sp' in file_name:\n",
    "                label = torch.tensor(1.0, dtype=torch.float)\n",
    "            elif 'ns' in file_name:\n",
    "                label = torch.tensor(0.0, dtype=torch.float)\n",
    "            \n",
    "            segment = loadmat(os.path.join(data_folder, file_name))['segment']\n",
    "            \n",
    "            # 1) wpli_matrix: (no_connectivities, num_freq_bands)\n",
    "            wpli_matrix = wpli_matrix_generator(segment, fs, nperseg, noverlap, freq_bands=freq_bands)\n",
    "            \n",
    "            \n",
    "            # 2) Thresholding, we can either use surrogates or not\n",
    "            adjacencies = threshold_func(wpli_matrix, USE_SURROGATES, segment, no_surrogates=no_surrogates, freq_FC_method='wpli', surrogate_thr=surrogate_thr, freq_bands=freq_bands)\n",
    "            del wpli_matrix\n",
    "            \n",
    "            adjacencies = [adjacencies_converter(adj, montage) for adj in adjacencies]\n",
    "            # adjacencies is a list of lists:\n",
    "            # outer list: different frequency bands\n",
    "            # inner list: src & dst 1-D torch.long tensors\n",
    "            \n",
    "            \n",
    "            patient_segments.append(torch.from_numpy(segment).float())\n",
    "            patient_adjs.append(adjacencies)\n",
    "            patient_labels.append(label)\n",
    "    \n",
    "    return patient_segments, patient_adjs, patient_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6824bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(patients_names):\n",
    "    group_segments = []\n",
    "    group_adjs = []\n",
    "    group_labels = []\n",
    "    \n",
    "    #with mp.Pool(processes=mp.cpu_count() - 1) as p:\n",
    "    #    for patient_segments, patient_adjs, patient_labels in p.imap_unordered(prep_patient_data, patients_names):\n",
    "    #        group_segments += patient_segments\n",
    "    #        group_adjs += patient_adjs\n",
    "    #        group_labels += patient_labels\n",
    "    \n",
    "    for patient_name in patients_names:\n",
    "        patient_segments, patient_adjs, patient_labels = prep_patient_data(patient_name)\n",
    "        group_segments += patient_segments\n",
    "        group_adjs += patient_adjs\n",
    "        group_labels += patient_labels\n",
    "    \n",
    "    return group_segments, group_adjs, group_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segments, train_adjs, train_labels = prepare_dataset(train_patients)\n",
    "val_segments, val_adjs, val_labels = prepare_dataset(val_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aefb7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_IQR_func(group_segments):\n",
    "    numbers = []\n",
    "    for segment in group_segments:\n",
    "        for row in range(segment.shape[0]):\n",
    "            for col in range(segment.shape[1]):\n",
    "                numbers.append(segment[row, col].item())\n",
    "    \n",
    "    quantiles = torch.tensor(numbers).quantile( torch.tensor([0.25, 0.5, 0.75]) )\n",
    "    median = quantiles[1].item()\n",
    "    IQR = quantiles[2].item() - quantiles[0].item()\n",
    "    \n",
    "    return median, IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_func(group_segments, median, IQR):\n",
    "    # Scales the group_segments list inplace\n",
    "    for idx in range(len(group_segments)):\n",
    "        group_segments[idx] = ((group_segments[idx] - median) / IQR)\n",
    "    \n",
    "    return group_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36894caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCALE:\n",
    "    median, IQR = median_IQR_func(train_segments)\n",
    "    train_segments = scaler_func(train_segments, median, IQR)\n",
    "    val_segments = scaler_func(val_segments, median, IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f93ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, segments, adjs, labels, flip_prob, montage):\n",
    "        self.segments = segments\n",
    "        self.adjs = adjs\n",
    "        self.labels = labels\n",
    "        self.flip_prob = flip_prob\n",
    "        \n",
    "        if flip_prob > 0:\n",
    "            self.idx_swaps_list, self.idx_swaps_dict = self.montage_swap_func(montage)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def montage_swap_func(montage):\n",
    "        name_to_idx_dict = {electrode_name: idx for idx, electrode_name in enumerate(montage)}\n",
    "        \n",
    "        label_swaps = [('Fp1', 'Fp2'), ('F7', 'F8'), ('F3', 'F4'), ('C3', 'C4'), ('P3', 'P4'), ('T3', 'T4'), ('T5', 'T6'), ('O1', 'O2')]\n",
    "        \n",
    "        idx_swaps_list = []\n",
    "        for e_left, e_right in label_swaps:\n",
    "            if (e_left in name_to_idx_dict) and (e_right in name_to_idx_dict):\n",
    "                idx_swaps_list.append((name_to_idx_dict[e_left], name_to_idx_dict[e_right]))\n",
    "        \n",
    "        idx_swaps_dict = {}\n",
    "        for e_left, e_right in idx_swaps_list:\n",
    "            idx_swaps_dict[e_left] = e_right\n",
    "            idx_swaps_dict[e_right] = e_left\n",
    "        \n",
    "        return idx_swaps_list, idx_swaps_dict\n",
    "    \n",
    "    \n",
    "    def flip_lr(self, segment, adj):\n",
    "        # flip segment ====> use self.idx_swaps_list\n",
    "        flipped_segment = torch.clone(segment)\n",
    "        for e_left, e_right in self.idx_swaps_list:\n",
    "            flipped_segment[e_left], flipped_segment[e_right] = segment[e_right], segment[e_left]\n",
    "        \n",
    "        # flip adj. ====> use self.idx_swaps_dict\n",
    "        # Note that adj is a list of lists:\n",
    "        # outer list: different frequency bands\n",
    "        # inner list: [src, dst] which are 1-D torch.long tensors of the same length\n",
    "        flipped_adj = []\n",
    "        for inner_list in adj:\n",
    "            flipped_src, flipped_dst = torch.clone(inner_list[0]), torch.clone(inner_list[1])\n",
    "            for i, (flipped_src_node, flipped_dst_node) in enumerate(zip(flipped_src, flipped_dst)):\n",
    "                flipped_src_node, flipped_dst_node = flipped_src_node.item(), flipped_dst_node.item()\n",
    "                if flipped_src_node in self.idx_swaps_dict:\n",
    "                    flipped_src[i] = self.idx_swaps_dict[flipped_src_node]\n",
    "                if flipped_dst_node in self.idx_swaps_dict:\n",
    "                    flipped_dst[i] = self.idx_swaps_dict[flipped_dst_node]\n",
    "            \n",
    "            flipped_adj.append([flipped_src, flipped_dst])\n",
    "        \n",
    "        return flipped_segment, flipped_adj\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        segment = self.segments[index]\n",
    "        adj = self.adjs[index]\n",
    "        num_nodes_in_example = torch.tensor(segment.shape[0])\n",
    "        if random.random() < self.flip_prob:\n",
    "            flipped_segment, flipped_adj = self.flip_lr(segment, adj)\n",
    "            return num_nodes_in_example, flipped_segment, self.labels[index], flipped_adj\n",
    "        else:\n",
    "            return num_nodes_in_example, segment, self.labels[index], adj\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f1a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    global freq_bands\n",
    "    \n",
    "    # The structure of batch is as follows:\n",
    "    # 1) outer most list ===> batch examples\n",
    "    # 2) tuple ===> 4 elements: (num_nodes_in_examples in the example, segment, label, connectivities lists)\n",
    "    # 3) middle list ===> freq_band_idx\n",
    "    # 4) inner most list ===> src, dst\n",
    "    \n",
    "    num_nodes_in_examples, segments, labels, adjs = zip(*batch)\n",
    "    del batch\n",
    "    \n",
    "    num_nodes_in_examples = torch.tensor(num_nodes_in_examples)  # 1-D: [#nodes_ex_1, #nodes_ex_2, ...., #nodes_ex_B]\n",
    "    segments = torch.cat(segments, dim=0)                        # (#nodes_ex_1 + #nodes_ex_2 + .... + #nodes_ex_B, 300)\n",
    "    labels = torch.tensor(labels)                                # 1-D: [label_ex_1, label_ex_2, ...., label_ex_B]\n",
    "    \n",
    "    # adjs now is a tuple of lists of lists of 1-D tensors\n",
    "    # outer most tuple ===> batch examples\n",
    "    # outer list ===> freq_band_idx\n",
    "    # inner list ===> src, dst\n",
    "    \n",
    "    num_freq_bands = len(freq_bands)\n",
    "    src_lists = [[] for _ in range(num_freq_bands)]\n",
    "    dst_lists = [[] for _ in range(num_freq_bands)]\n",
    "    increment = 0\n",
    "    for example_idx, step in enumerate(num_nodes_in_examples):\n",
    "        for freq_band_idx in range(num_freq_bands):\n",
    "            src_lists[freq_band_idx].append(increment + adjs[example_idx][freq_band_idx][0])\n",
    "            dst_lists[freq_band_idx].append(increment + adjs[example_idx][freq_band_idx][1])\n",
    "            \n",
    "        increment += step.item()\n",
    "    \n",
    "    \n",
    "    indices = []\n",
    "    for src_list, dst_list in zip(src_lists, dst_lists):\n",
    "        src = torch.cat(src_list, dim=-1)\n",
    "        dst = torch.cat(dst_list, dim=-1)\n",
    "        \n",
    "        i = torch.stack([dst, src], dim=0)\n",
    "        indices.append(i)\n",
    "    \n",
    "    return num_nodes_in_examples, segments, labels, *indices\n",
    "    \n",
    "    '''\n",
    "    sparse_matrices = []     # 1 sparse matrix per frequency band\n",
    "    total_num_nodes = num_nodes_in_examples.sum().item()\n",
    "    for src_list, dst_list in zip(src_lists, dst_lists):\n",
    "        src = torch.cat(src_list, dim=-1)\n",
    "        dst = torch.cat(dst_list, dim=-1)\n",
    "        \n",
    "        i = torch.stack([dst, src], dim=0)\n",
    "        v = torch.ones((len(src),), dtype=torch.float)\n",
    "        sparse_mat = torch.sparse_coo_tensor(i, v, [total_num_nodes, total_num_nodes])\n",
    "        sparse_matrices.append(sparse_mat)\n",
    "    \n",
    "    \n",
    "    return num_nodes_in_examples, segments, labels, *sparse_matrices\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f8efded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, no_input_features, H, d_qk, d_v, dim, bias_att=True):\n",
    "        super().__init__()\n",
    "        self.H = H\n",
    "        self.d_qk = d_qk\n",
    "        self.d_v = d_v\n",
    "        \n",
    "        # dim: dimension across which to attend\n",
    "        if dim not in {-1, -2}:\n",
    "            raise NameError('Error: Enforce your attention dimension to either -1 or -2 !')\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.q = torch.nn.Parameter(torch.empty(H, d_qk))\n",
    "        torch.nn.init.xavier_normal_(self.q)\n",
    "        \n",
    "        self.att_lin = torch.nn.Linear(in_features=no_input_features, out_features=(H * d_qk) + (H * d_v), bias=bias_att)\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def qkv_func(q, k, v):\n",
    "        \n",
    "        # num_freq_bands: F or E or T\n",
    "        # q: (B, H, 1, d_qk)\n",
    "        # k: (B, H, F or E or T, d_qk)\n",
    "        # v: (B, H, F or E or T, d_v)\n",
    "        \n",
    "        B, H, F, d_qk = k.shape\n",
    "        d_v = v.shape[-1]\n",
    "        \n",
    "        logits = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_qk)     # logits: (B, H, 1, F)\n",
    "        s_m = logits.softmax(dim=-1)                                        # s_m: (B, H, 1, F)\n",
    "        \n",
    "        # (B, H, 1, F) * (B, H, F, d_v) = (B, H, 1, d_v) ===permute===> (B, 1, H, d_v) ===reshape===> (B, H * d_v)\n",
    "        y = torch.matmul(s_m, v).transpose(-2,-3).reshape((B, H * d_v))\n",
    "        \n",
    "        return y, s_m    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.dim == -1:\n",
    "            # x: (B, C=no_input_features, T or E)\n",
    "            x.transpose_(-1, -2)\n",
    "        \n",
    "        # x: (B, T or E or F, C=no_input_features)\n",
    "        B, F, _ = x.shape\n",
    "        \n",
    "        # (B, T or E, C=no_input_features) ====self.att_lin====> ( B, F, (H * d_qk) + (H * d_v) )\n",
    "        k, v = self.att_lin(x).split(split_size=[self.H * self.d_qk, self.H * self.d_v], dim=-1)\n",
    "        \n",
    "        q = self.q.expand(B, 1, self.H, self.d_qk).transpose(-2, -3)   # q: (B, self.H, 1, self.d_qk)\n",
    "        k = k.reshape((B, F, self.H, self.d_qk)).transpose(-2, -3)     # k: (B, self.H, F, self.d_qk)\n",
    "        v = v.reshape((B, F, self.H, self.d_v)).transpose(-2, -3)      # v: (B, self.H, F, self.d_v)\n",
    "        \n",
    "        y, s_m = self.qkv_func(q, k, v)          # y: (B, self.H * self.d_v), s_m: (B, self.H, 1, F)\n",
    "        \n",
    "        if self.dim == -1:\n",
    "            x.transpose_(-1, -2)                                       # (B, C=no_input_features, F)\n",
    "        \n",
    "        # overall, x preserves its inputted shape & y shape (B, self.H * self.d_v)\n",
    "        return y, s_m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineWarmupScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, warmup, max_num_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_num_iters\n",
    "        super().__init__(optimizer)\n",
    "    \n",
    "    \n",
    "    def get_lr(self):\n",
    "        # returns a list of the learning rates\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "    \n",
    "    \n",
    "    def get_lr_factor(self, epoch):\n",
    "        # Optional method that computes lr_factor, NOT learning rate itself.\n",
    "        if epoch <= self.warmup:\n",
    "            slope = (1 - 0) / (self.warmup - 0)\n",
    "            lr_factor = slope * epoch\n",
    "        else:\n",
    "            f = 1 / (2 * (self.max_num_iters - self.warmup))\n",
    "            lr_factor = 0.5 * ( 1 + math.cos( 2 * math.pi * f * (epoch - self.warmup) ) )\n",
    "        \n",
    "        return lr_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_validation_loss = math.inf\n",
    "best_epoch = 0\n",
    "best_model_state = None\n",
    "AP_at_min_val_loss = 0.\n",
    "EARLY_STOPPING = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a805cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLightningModule(pl.LightningModule):\n",
    "    def __init__(self, num_freq_bands, dedicated_vgg=False, eps=0., train_eps=False, dedicated_GIN=True, attention=True, heads=1, d_qk=15, d_v=15):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.register_buffer('num_freq_bands', torch.tensor(num_freq_bands, dtype=torch.int))\n",
    "        \n",
    "        if dedicated_vgg:\n",
    "            self.vggs = torch.nn.ModuleList([self.construct_vgg() for _ in range(num_freq_bands)])\n",
    "        else:\n",
    "            self.vggs = torch.nn.ModuleList([self.construct_vgg()])\n",
    "        \n",
    "        \n",
    "        if dedicated_GIN:\n",
    "            self.h1_lin = torch.nn.ModuleList([torch.nn.Linear(in_features=13, out_features=13) for _ in range(num_freq_bands)])\n",
    "            self.h2_lin = torch.nn.ModuleList([torch.nn.Linear(in_features=13, out_features=13) for _ in range(num_freq_bands)])\n",
    "            self.h3_lin = torch.nn.ModuleList([torch.nn.Linear(in_features=13, out_features=13) for _ in range(num_freq_bands)])\n",
    "        else:\n",
    "            self.h1_lin = torch.nn.ModuleList([torch.nn.Linear(in_features=13, out_features=13)])\n",
    "            self.h2_lin = torch.nn.ModuleList([torch.nn.Linear(in_features=13, out_features=13)])\n",
    "            self.h3_lin = torch.nn.ModuleList([torch.nn.Linear(in_features=13, out_features=13)])\n",
    "        \n",
    "        \n",
    "        l = len(self.h1_lin)\n",
    "        if train_eps:\n",
    "            self.eps1 = torch.nn.ParameterList([torch.nn.Parameter(torch.tensor(eps)) for _ in range(l)])\n",
    "            self.eps2 = torch.nn.ParameterList([torch.nn.Parameter(torch.tensor(eps)) for _ in range(l)])\n",
    "            self.eps3 = torch.nn.ParameterList([torch.nn.Parameter(torch.tensor(eps)) for _ in range(l)])\n",
    "        else:\n",
    "            self.register_buffer('eps1', torch.tensor([eps for _ in range(l)]))\n",
    "            self.register_buffer('eps2', torch.tensor([eps for _ in range(l)]))\n",
    "            self.register_buffer('eps3', torch.tensor([eps for _ in range(l)]))\n",
    "        \n",
    "        self.attention = attention\n",
    "        if attention:\n",
    "            self.m_h_a = MultiHeadAttention(4 * 13, heads, d_qk, d_v, -2)\n",
    "            self.class_mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(in_features=heads*d_v, out_features=10),\n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Dropout(p=p_dropout),\n",
    "                torch.nn.Linear(in_features=10, out_features=5),\n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Dropout(p=p_dropout),\n",
    "                torch.nn.Linear(in_features=5, out_features=1)\n",
    "            )\n",
    "        else:\n",
    "            self.class_mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(in_features=num_freq_bands*4*13, out_features=30),\n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Dropout(p=p_dropout),\n",
    "                torch.nn.Linear(in_features=30, out_features=10),\n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Dropout(p=p_dropout),\n",
    "                torch.nn.Linear(in_features=10, out_features=1)\n",
    "            )\n",
    "        \n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.automatic_optimization = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def construct_vgg():\n",
    "        return torch.nn.Sequential(\n",
    "            # (1, #nodes_ex_1 + .... + #nodes_ex_B, 300) ====> (2, #nodes_ex_1 + .... + #nodes_ex_B, 298)\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (2, #nodes_ex_1 + .... + #nodes_ex_B, 298) ====> (3, #nodes_ex_1 + .... + #nodes_ex_B, 296)\n",
    "            torch.nn.Conv2d(in_channels=2, out_channels=3, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (3, #nodes_ex_1 + .... + #nodes_ex_B, 296) ==/2==> (3, #nodes_ex_1 + .... + #nodes_ex_B, 148)\n",
    "            #torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(1,2), stride=(1,2)),\n",
    "            torch.nn.MaxPool2d(kernel_size=(1,2)),\n",
    "            \n",
    "            # (3, #nodes_ex_1 + .... + #nodes_ex_B, 148) ====> (4, #nodes_ex_1 + .... + #nodes_ex_B, 146)\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=4, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (4, #nodes_ex_1 + .... + #nodes_ex_B, 146) ====> (5, #nodes_ex_1 + .... + #nodes_ex_B, 144)\n",
    "            torch.nn.Conv2d(in_channels=4, out_channels=5, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (5, #nodes_ex_1 + .... + #nodes_ex_B, 144) ==/2==> (5, #nodes_ex_1 + .... + #nodes_ex_B, 72)\n",
    "            #torch.nn.Conv2d(in_channels=5, out_channels=5, kernel_size=(1,2), stride=(1,2)),\n",
    "            torch.nn.MaxPool2d(kernel_size=(1,2)),\n",
    "            \n",
    "            # (5, #nodes_ex_1 + .... + #nodes_ex_B, 72) ====> (6, #nodes_ex_1 + .... + #nodes_ex_B, 70)\n",
    "            torch.nn.Conv2d(in_channels=5, out_channels=6, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (6, #nodes_ex_1 + .... + #nodes_ex_B, 70) ====> (7, #nodes_ex_1 + .... + #nodes_ex_B, 68)\n",
    "            torch.nn.Conv2d(in_channels=6, out_channels=7, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (7, #nodes_ex_1 + .... + #nodes_ex_B, 68) ====> (8, #nodes_ex_1 + .... + #nodes_ex_B, 66)\n",
    "            torch.nn.Conv2d(in_channels=7, out_channels=8, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (8, #nodes_ex_1 + .... + #nodes_ex_B, 66) ====> (9, #nodes_ex_1 + .... + #nodes_ex_B, 64)\n",
    "            torch.nn.Conv2d(in_channels=8, out_channels=9, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (9, #nodes_ex_1 + .... + #nodes_ex_B, 64) ==/2==> (9, #nodes_ex_1 + .... + #nodes_ex_B, 32)\n",
    "            #torch.nn.Conv2d(in_channels=9, out_channels=9, kernel_size=(1,2), stride=(1,2)),\n",
    "            torch.nn.MaxPool2d(kernel_size=(1,2)),\n",
    "            \n",
    "            # (9, #nodes_ex_1 + .... + #nodes_ex_B, 32) ====> (10, #nodes_ex_1 + .... + #nodes_ex_B, 30)\n",
    "            torch.nn.Conv2d(in_channels=9, out_channels=10, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (10, #nodes_ex_1 + .... + #nodes_ex_B, 30) ====> (11, #nodes_ex_1 + .... + #nodes_ex_B, 28)\n",
    "            torch.nn.Conv2d(in_channels=10, out_channels=11, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (11, #nodes_ex_1 + .... + #nodes_ex_B, 28) ====> (12, #nodes_ex_1 + .... + #nodes_ex_B, 26)\n",
    "            torch.nn.Conv2d(in_channels=11, out_channels=12, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (12, #nodes_ex_1 + .... + #nodes_ex_B, 26) ====> (13, #nodes_ex_1 + .... + #nodes_ex_B, 24)\n",
    "            torch.nn.Conv2d(in_channels=12, out_channels=13, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (13, #nodes_ex_1 + .... + #nodes_ex_B, 24) ==/2==> (13, #nodes_ex_1 + .... + #nodes_ex_B, 12)\n",
    "            #torch.nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(1,2), stride=(1,2)),\n",
    "            torch.nn.MaxPool2d(kernel_size=(1,2)),\n",
    "            \n",
    "            # (13, #nodes_ex_1 + .... + #nodes_ex_B, 12) ====> (13, #nodes_ex_1 + .... + #nodes_ex_B, 10)\n",
    "            torch.nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (13, #nodes_ex_1 + .... + #nodes_ex_B, 10) ====> (13, #nodes_ex_1 + .... + #nodes_ex_B, 8)\n",
    "            torch.nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (13, #nodes_ex_1 + .... + #nodes_ex_B, 8) ====> (13, #nodes_ex_1 + .... + #nodes_ex_B, 6)\n",
    "            torch.nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (13, #nodes_ex_1 + .... + #nodes_ex_B, 6) ====> (13, #nodes_ex_1 + .... + #nodes_ex_B, 4)\n",
    "            torch.nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (13, #nodes_ex_1 + .... + #nodes_ex_B, 4) ====> (13, #nodes_ex_1 + .... + #nodes_ex_B, 2)\n",
    "            torch.nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(1, 3)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout),\n",
    "            # (13, #nodes_ex_1 + .... + #nodes_ex_B, 2) ====> (13, #nodes_ex_1 + .... + #nodes_ex_B, 1)\n",
    "            torch.nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(1, 2)),\n",
    "            torch.nn.LeakyReLU(), torch.nn.Dropout(p=p_dropout)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def positional_embedding(xs, num_nodes_in_examples):\n",
    "        # xs is a list of a single tensor OR num_freq_bands tensors. Each tensor in this list\n",
    "        # has the shape (#nodes_ex_1 + #nodes_ex_2 + .... + #nodes_ex_B, d)\n",
    "        \n",
    "        # num_nodes_in_examples: 1-D tensor [#nodes_ex_1, #nodes_ex_2, ...., #nodes_ex_B]\n",
    "        # xs is a list of 2-D tensors. Each tensor has the following structure:\n",
    "        # 1st row: embedding of 1st electrode in 1st example\n",
    "        # 2nd row: embedding of 2nd electrode in 1st example\n",
    "        # 3rd row: embedding of 3rd electrode in 1st example\n",
    "        # ....\n",
    "        # (#nodes_ex_1)th row: embedding of (#nodes_ex_1)th electrode in 1st example\n",
    "        # (#nodes_ex_1 + 1)th row: embedding of 1st electrode in 2nd example\n",
    "        \n",
    "        # Add positional embedding to make the GNN differentiate between electrodes\n",
    "        unique_num_electrodes_in_examples = num_nodes_in_examples.unique()\n",
    "        \n",
    "        device = xs[0].device\n",
    "        d = xs[0].shape[1]\n",
    "        \n",
    "        pe_dic = {}\n",
    "        for E in unique_num_electrodes_in_examples:\n",
    "            E = E.item()\n",
    "            \n",
    "            pe = torch.zeros((d, E), device=device)\n",
    "            e = torch.arange(E, device=device).reshape(1, E)\n",
    "            \n",
    "            col_len = math.ceil(d / 2)\n",
    "            col = torch.arange(start=1, end=col_len+1, device=device).reshape(col_len, 1)\n",
    "            \n",
    "            angle = e / (100 ** ((2 * col) / d))\n",
    "            sin = torch.sin(angle)\n",
    "            \n",
    "            if d % 2 == 0:\n",
    "                cos = torch.cos(angle)\n",
    "            else:\n",
    "                cos = torch.cos(angle[0:-1])\n",
    "            \n",
    "            #cos = torch.where(torch.tensor(d % 2 == 0, device=x.device), torch.cos(angle), torch.cos(angle[0:-1]))\n",
    "            \n",
    "            pe[0::2, :] = sin\n",
    "            pe[1::2, :] = cos\n",
    "            \n",
    "            pe.transpose_(-1, -2)     # pe: (E, d)\n",
    "            pe_dic[E] = pe\n",
    "        \n",
    "        \n",
    "        # pe_dic: dictionary mapping the number of electrodes (E) to tensor of shape (E, d)\n",
    "        start_idx_xs = 0\n",
    "        for num_nodes_in_example in num_nodes_in_examples:\n",
    "            num_nodes_in_example = num_nodes_in_example.item()\n",
    "            end_idx_xs = start_idx_xs + num_nodes_in_example\n",
    "            \n",
    "            for i in range(len(xs)):\n",
    "                xs[i][start_idx_xs : end_idx_xs] = xs[i][start_idx_xs : end_idx_xs] + pe_dic[num_nodes_in_example]\n",
    "            \n",
    "            start_idx_xs = end_idx_xs\n",
    "        \n",
    "        return xs\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def gin_forward(H_before, sparse_matrices, eps, h):\n",
    "        H_after = []\n",
    "        for freq_band_idx, sparse_mat in enumerate(sparse_matrices):\n",
    "            if len(h) == 1:\n",
    "                h_iter = h[0]\n",
    "                eps_iter = eps[0]\n",
    "            else:\n",
    "                h_iter = h[freq_band_idx]\n",
    "                eps_iter = eps[freq_band_idx]\n",
    "            \n",
    "            y = ((1 + eps_iter) * H_before[freq_band_idx]) + torch.sparse.mm(sparse_mat, H_before[freq_band_idx])\n",
    "            y = h_iter(y)\n",
    "            y = torch.nn.functional.leaky_relu(y)\n",
    "            y = torch.nn.functional.dropout(y, p=p_dropout)\n",
    "            H_after.append(y)\n",
    "        \n",
    "        return H_after\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def construct_H(num_nodes_in_examples, *Hs):\n",
    "        num_freq_bands = len(Hs[0])\n",
    "        batch_size = num_nodes_in_examples.numel()\n",
    "        \n",
    "        H = []\n",
    "        for freq_band_idx in range(num_freq_bands):\n",
    "            lis = [H_i[freq_band_idx] for H_i in Hs]\n",
    "            H.append(torch.cat(lis, dim=-1))\n",
    "        \n",
    "        index = torch.arange(start=0, end=batch_size, step=1, device=num_nodes_in_examples.device)\n",
    "        index = index.repeat_interleave(num_nodes_in_examples)\n",
    "        \n",
    "        H = [torch_scatter.scatter(h, index, dim=0) for h in H]\n",
    "        H = [h.reshape(batch_size, 1, -1) for h in H]\n",
    "        H = torch.cat(H, dim=1)                    # H: (B, num_freq_bands, -1)\n",
    "        \n",
    "        return H\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, num_nodes_in_examples, segments, sparse_matrices):\n",
    "        # num_nodes_in_examples: 1-D tensor [#nodes_ex_1, #nodes_ex_2, ...., #nodes_ex_B]\n",
    "        # segments: (#nodes_ex_1 + #nodes_ex_2 + .... + #nodes_ex_B, 300)\n",
    "        # sparse_matrices is a list. Each item of that list is a sparse matrix representing the\n",
    "        # adjacency of a specific frequency band\n",
    "        \n",
    "        B = num_nodes_in_examples.numel()\n",
    "        num_freq_bands = len(sparse_matrices)\n",
    "        \n",
    "        xs = []\n",
    "        for vgg in self.vggs:\n",
    "            x = vgg(segments.unsqueeze(dim=0))     # x: (L, #nodes_ex_1 + #nodes_ex_2 + .... + #nodes_ex_B, 1)\n",
    "            x.squeeze_(dim=-1)                     # x: (L, #nodes_ex_1 + #nodes_ex_2 + .... + #nodes_ex_B)\n",
    "            x.transpose_(-1, -2)                   # x: (#nodes_ex_1 + #nodes_ex_2 + .... + #nodes_ex_B, L=13)\n",
    "            xs.append(x)\n",
    "        \n",
    "        xs = self.positional_embedding(xs, num_nodes_in_examples)\n",
    "        \n",
    "        if (len(xs) == 1) and (num_freq_bands > 1):\n",
    "            H0 = xs * num_freq_bands\n",
    "        else:\n",
    "            H0 = xs\n",
    "        \n",
    "        H1 = self.gin_forward(H0, sparse_matrices, self.eps1, self.h1_lin)\n",
    "        \n",
    "        H2 = self.gin_forward(H1, sparse_matrices, self.eps2, self.h2_lin)\n",
    "        \n",
    "        H3 = self.gin_forward(H2, sparse_matrices, self.eps3, self.h3_lin)\n",
    "        \n",
    "        # Each of H0, H1, H2, and H3 are lists of length num_freq_bands.\n",
    "        # Each item in that list is a 2-D tensor with\n",
    "        # #rows = #nodes_ex_1 + #nodes_ex_2 + .... + #nodes_ex_B\n",
    "        \n",
    "        # collapse_H\n",
    "        H = self.construct_H(num_nodes_in_examples, H0, H1, H2, H3)     # H: (B, num_freq_bands, 4 * 13)\n",
    "        \n",
    "        if self.attention:\n",
    "            logits, s_m = self.m_h_a(H)     # logits: (B, self.H * self.d_v), s_m: (B, self.H, 1, F)\n",
    "            logits = self.class_mlp(logits)              # (B, 1)\n",
    "        else:\n",
    "            logits = H.reshape(B, -1)       # (B, num_freq_bands*4*13)\n",
    "            logits = self.class_mlp(logits)     # (B, 1)\n",
    "        \n",
    "        logits.squeeze_(dim=-1)             # (B,)\n",
    "        \n",
    "        if self.attention:\n",
    "            return logits, s_m\n",
    "        else:\n",
    "            return logits\n",
    "    \n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), weight_decay=0)\n",
    "        cosine_scheduler = CosineWarmupScheduler(optimizer=optimizer, warmup=100, max_num_iters=self.trainer.max_epochs)\n",
    "        swa_scheduler = SWALR(optimizer, swa_lr=0.0001, anneal_epochs=100, anneal_strategy='cos')\n",
    "        return [optimizer], [cosine_scheduler, swa_scheduler]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = CustomDataset(train_segments, train_adjs, train_labels, 0.5, montage)\n",
    "        # mp.cpu_count()-1\n",
    "        return torch.utils.data.DataLoader(dataset, batch_size=train_B, shuffle=True, num_workers=0,\n",
    "                                           collate_fn=collate_fn, pin_memory=True, drop_last=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        dataset = CustomDataset(val_segments, val_adjs, val_labels, 0, montage)\n",
    "        return torch.utils.data.DataLoader(dataset, batch_size=val_B, shuffle=False, num_workers=0,\n",
    "                                           collate_fn=collate_fn, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #num_nodes_in_examples, segments, y, *sparse_matrices = batch\n",
    "        num_nodes_in_examples, segments, y, *indices = batch\n",
    "        \n",
    "        total_num_nodes = num_nodes_in_examples.sum().item()\n",
    "        sparse_matrices = []\n",
    "        for i in indices:\n",
    "            v = torch.ones((i.shape[1],), dtype=torch.float, device=i.device)\n",
    "            sparse_mat = torch.sparse_coo_tensor(i, v, [total_num_nodes, total_num_nodes])\n",
    "            sparse_matrices.append(sparse_mat)\n",
    "        \n",
    "        \n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if self.attention:\n",
    "                logits_before_optimizer_step, s_m = self(num_nodes_in_examples, segments, sparse_matrices)\n",
    "            else:\n",
    "                logits_before_optimizer_step = self(num_nodes_in_examples, segments, sparse_matrices)\n",
    "            loss_before_optimizer_step = self.criterion(logits_before_optimizer_step, y)\n",
    "        self.train()\n",
    "        \n",
    "        \n",
    "        opt = self.optimizers()\n",
    "        def closure():\n",
    "            if self.attention:\n",
    "                logits, s_m = self(num_nodes_in_examples, segments, sparse_matrices)\n",
    "            else:\n",
    "                logits = self(num_nodes_in_examples, segments, sparse_matrices)\n",
    "            loss = self.criterion(logits, y)\n",
    "            opt.zero_grad()\n",
    "            self.manual_backward(loss)\n",
    "            return loss\n",
    "        \n",
    "        opt.step(closure=closure)\n",
    "        \n",
    "        return {'loss_before_optimizer_step': loss_before_optimizer_step.detach()}\n",
    "    \n",
    "    \n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        if self.global_rank == 0:\n",
    "            train_loss = torch.stack([dic['loss_before_optimizer_step'] for dic in training_step_outputs]).mean()\n",
    "            print(f'Epoch: {self.current_epoch}')\n",
    "            print(f'Training loss BEFORE optimizer step: {round(train_loss.item(), 5)}')\n",
    "            print('--------------------------------------')\n",
    "    \n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # num_nodes_in_examples, segments, y, *sparse_matrices = batch\n",
    "        num_nodes_in_examples, segments, y, *indices = batch\n",
    "        \n",
    "        total_num_nodes = num_nodes_in_examples.sum().item()\n",
    "        sparse_matrices = []\n",
    "        for i in indices:\n",
    "            v = torch.ones((i.shape[1],), dtype=torch.float, device=i.device)\n",
    "            sparse_mat = torch.sparse_coo_tensor(i, v, [total_num_nodes, total_num_nodes])\n",
    "            sparse_matrices.append(sparse_mat)\n",
    "        \n",
    "        \n",
    "        if self.attention:\n",
    "            logits, s_m = self(num_nodes_in_examples, segments, sparse_matrices)\n",
    "        else:\n",
    "            logits = self(num_nodes_in_examples, segments, sparse_matrices)\n",
    "        loss = self.criterion(logits, y)\n",
    "        return {'loss': loss, 'y': y, 'logits': logits}\n",
    "    \n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        global min_validation_loss, best_epoch, best_model_state, AP_at_min_val_loss\n",
    "        \n",
    "        swa_start_epoch = 1000\n",
    "        \n",
    "        cosine_scheduler, swa_scheduler = self.lr_schedulers()\n",
    "        \n",
    "        if self.current_epoch > 0:\n",
    "            if self.current_epoch < swa_start_epoch:\n",
    "                cosine_scheduler.step()\n",
    "            else:\n",
    "                swa_scheduler.step()\n",
    "            \n",
    "        \n",
    "        \n",
    "        if self.global_rank == 0:\n",
    "            \n",
    "            if self.current_epoch > (swa_start_epoch + swa_scheduler.anneal_epochs):\n",
    "                swa_model.update_parameters(self)\n",
    "                \n",
    "            \n",
    "            val_loss = torch.stack([dic['loss'] for dic in validation_step_outputs]).mean()\n",
    "            val_loss = val_loss.item()\n",
    "            print(f'val_loss: {val_loss}')\n",
    "            \n",
    "            y = torch.cat([dic['y'] for dic in validation_step_outputs]).cpu()\n",
    "            logits = torch.cat([dic['logits'] for dic in validation_step_outputs]).cpu()\n",
    "            pred = torch.sigmoid(logits)\n",
    "            \n",
    "            y = np.array(y)\n",
    "            pred = np.array(pred)\n",
    "            \n",
    "            try:\n",
    "                validation_AP = average_precision_score(y, pred)\n",
    "                \n",
    "                if (val_loss < min_validation_loss) and (self.current_epoch > 1):\n",
    "                    min_validation_loss = val_loss\n",
    "                    best_epoch = self.current_epoch\n",
    "                    best_model_state = deepcopy(self.state_dict())\n",
    "                    AP_at_min_val_loss = validation_AP\n",
    "                \n",
    "                \n",
    "                print(f'validation_AP = {round(validation_AP, 5)} ... AP_at_min_val_loss = {round(AP_at_min_val_loss, 5)} @ epoch {best_epoch}')\n",
    "                \n",
    "            except ValueError:\n",
    "                print(f'ValueError @ epoch: {self.current_epoch} ====> y = {y}')\n",
    "            \n",
    "            print('=======================================================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2886b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_freq_bands = len(freq_bands)\n",
    "my_lightning_module = CustomLightningModule(num_freq_bands, dedicated_vgg=dedicated_vgg, eps=eps, train_eps=train_eps, dedicated_GIN=dedicated_GIN, attention=attention, heads=1, d_qk=25, d_v=25)\n",
    "\n",
    "swa_model = AveragedModel(my_lightning_module)\n",
    "\n",
    "trainer = pl.Trainer(gpus=0, enable_checkpointing=False, enable_progress_bar=False, logger=False, max_epochs=400)\n",
    "\n",
    "trainer.fit(my_lightning_module)\n",
    "\n",
    "torch.optim.swa_utils.update_bn(my_lightning_module.train_dataloader(), swa_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ee7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f'models/g2_FC_GIN_10k_AP_{round(100 * AP_at_min_val_loss, 2)}.pt'\n",
    "torch.save(best_model_state, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893323a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a930dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffb1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "490ae63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "num_freq_bands = len(freq_bands)\n",
    "model = CustomLightningModule(num_freq_bands, dedicated_vgg=dedicated_vgg,\n",
    "                              eps=eps, train_eps=train_eps,\n",
    "                              dedicated_GIN=dedicated_GIN, attention=attention,\n",
    "                              heads=1, d_qk=25, d_v=25)\n",
    "\n",
    "#IEDs_names = [item for item in os.listdir(data_folder) if 'sp' in item]\n",
    "NIEDs_names = [item for item in os.listdir(data_folder) if 'ns' in item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4017372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [item for item in os.listdir('models/') if 'g1_FC_GIN' in item]\n",
    "g1_model_name = max(lis)\n",
    "train_segments, _, _ = prepare_dataset(g2 + g3 + g4 + g5)\n",
    "g1_median, g1_IQR = median_IQR_func(train_segments)\n",
    "\n",
    "\n",
    "lis = [item for item in os.listdir('models/') if 'g2_FC_GIN' in item]\n",
    "g2_model_name = max(lis)\n",
    "train_segments, _, _ = prepare_dataset(g1 + g3 + g4 + g5)\n",
    "g2_median, g2_IQR = median_IQR_func(train_segments)\n",
    "\n",
    "\n",
    "lis = [item for item in os.listdir('models/') if 'g3_FC_GIN' in item]\n",
    "g3_model_name = max(lis)\n",
    "train_segments, _, _ = prepare_dataset(g1 + g2 + g4 + g5)\n",
    "g3_median, g3_IQR = median_IQR_func(train_segments)\n",
    "\n",
    "\n",
    "lis = [item for item in os.listdir('models/') if 'g4_FC_GIN' in item]\n",
    "g4_model_name = max(lis)\n",
    "train_segments, _, _ = prepare_dataset(g1 + g2 + g3 + g5)\n",
    "g4_median, g4_IQR = median_IQR_func(train_segments)\n",
    "\n",
    "\n",
    "lis = [item for item in os.listdir('models/') if 'g5_FC_GIN' in item]\n",
    "g5_model_name = max(lis)\n",
    "train_segments, _, _ = prepare_dataset(g1 + g2 + g3 + g4)\n",
    "g5_median, g5_IQR = median_IQR_func(train_segments)\n",
    "\n",
    "\n",
    "#s = pd.Series(index=IEDs_names, dtype='float64')\n",
    "s = pd.Series(index=NIEDs_names, dtype='float64')\n",
    "\n",
    "\n",
    "#for IED_name in IEDs_names:\n",
    "for NIED_name in NIEDs_names:\n",
    "    #segment = loadmat(os.path.join(data_folder, IED_name))['segment']\n",
    "    segment = loadmat(os.path.join(data_folder, NIED_name))['segment']\n",
    "            \n",
    "    # 1) wpli_matrix: (no_connectivities, num_freq_bands)\n",
    "    wpli_matrix = wpli_matrix_generator(segment, fs, nperseg, noverlap, freq_bands=freq_bands)\n",
    "    \n",
    "    \n",
    "    # 2) Thresholding, we can either use surrogates or not\n",
    "    adjacencies = threshold_func(wpli_matrix, USE_SURROGATES, segment, no_surrogates=no_surrogates, freq_FC_method='wpli', surrogate_thr=surrogate_thr, freq_bands=freq_bands)\n",
    "    del wpli_matrix\n",
    "    \n",
    "    adjacencies = [adjacencies_converter(adj, montage) for adj in adjacencies]\n",
    "    # adjacencies is a list of lists:\n",
    "    # outer list: different frequency bands\n",
    "    # inner list: src & dst 1-D torch.long tensors\n",
    "    \n",
    "    sparse_matrices = []\n",
    "    for adj in adjacencies:\n",
    "        src, dst = adj\n",
    "        i = torch.stack([dst, src], dim=0)\n",
    "        v = torch.ones((i.shape[1],), dtype=torch.float)\n",
    "        sparse_matrices.append( torch.sparse_coo_tensor(i, v, [19, 19]) )\n",
    "    \n",
    "    \n",
    "    segment = torch.tensor(segment).float()\n",
    "    \n",
    "    #patient_name = IED_name[: IED_name.find('_')]\n",
    "    patient_name = NIED_name[: NIED_name.find('_')]\n",
    "    \n",
    "    if patient_name in g1:\n",
    "        segment = (segment - g1_median) / g1_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g1_model_name}'))\n",
    "    elif patient_name in g2:\n",
    "        segment = (segment - g2_median) / g2_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g2_model_name}'))\n",
    "    elif patient_name in g3:\n",
    "        segment = (segment - g3_median) / g3_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g3_model_name}'))\n",
    "    elif patient_name in g4:\n",
    "        segment = (segment - g4_median) / g4_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g4_model_name}'))\n",
    "    elif patient_name in g5:\n",
    "        segment = (segment - g5_median) / g5_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g5_model_name}'))\n",
    "    else:\n",
    "        raise NameError('Unknown Patient')\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if attention:\n",
    "        logit, _ = model(torch.tensor([19]), segment, sparse_matrices)\n",
    "    else:\n",
    "        logit = model(torch.tensor([19]), segment, sparse_matrices)\n",
    "    \n",
    "    \n",
    "    #s.at[IED_name] = torch.sigmoid(logit).item()\n",
    "    s.at[NIED_name] = torch.sigmoid(logit).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f80ccdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RC_24_ns.mat      8.600377e-03\n",
       "FEsg_38_ns.mat    1.120687e-04\n",
       "HB_2_ns.mat       4.159114e-08\n",
       "FEsg_26_ns.mat    2.963187e-01\n",
       "FigSa_9_ns.mat    4.961883e-02\n",
       "                      ...     \n",
       "LM_3_ns.mat       6.453300e-06\n",
       "RC_6_ns.mat       8.747430e-06\n",
       "FEsg_19_ns.mat    1.311908e-01\n",
       "NKra_10_ns.mat    6.252312e-03\n",
       "PAT48_ns_6.mat    1.284350e-04\n",
       "Length: 593, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d83bbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.ExcelWriter('IEDs_results.xlsx', mode='a') as writer:\n",
    "with pd.ExcelWriter('NIEDs_results.xlsx', mode='a') as writer:\n",
    "    s.to_excel(writer, sheet_name='FC_GIN', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf3105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6198870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38ff06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b943680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWA\n",
    "\n",
    "loss_list = []\n",
    "y_list = []\n",
    "logits_list = []\n",
    "s_m_list = []\n",
    "\n",
    "dataset = CustomDataset(val_segments, val_adjs, val_labels, 0, montage)\n",
    "dl = torch.utils.data.DataLoader(dataset, batch_size=val_B, shuffle=False, num_workers=mp.cpu_count()-1,\n",
    "                                 collate_fn=collate_fn, pin_memory=False, drop_last=False)\n",
    "\n",
    "swa_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in dl:\n",
    "        # num_nodes_in_examples, segments, y, *sparse_matrices = batch\n",
    "        num_nodes_in_examples, segments, y, *indices = batch\n",
    "        \n",
    "        total_num_nodes = num_nodes_in_examples.sum().item()\n",
    "        sparse_matrices = []\n",
    "        for i in indices:\n",
    "            v = torch.ones((i.shape[1],), dtype=torch.float, device=i.device)\n",
    "            sparse_mat = torch.sparse_coo_tensor(i, v, [total_num_nodes, total_num_nodes])\n",
    "            sparse_matrices.append(sparse_mat)\n",
    "        \n",
    "        \n",
    "        if attention:\n",
    "            logits, s_m = swa_model(num_nodes_in_examples, segments, sparse_matrices)\n",
    "        else:\n",
    "            logits = swa_model(num_nodes_in_examples, segments, sparse_matrices)\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(logits, y)\n",
    "        \n",
    "        loss_list.append(loss)\n",
    "        y_list.append(y)\n",
    "        logits_list.append(logits)\n",
    "        s_m_list.append(s_m)\n",
    "    \n",
    "    loss = torch.stack(loss_list)\n",
    "    y = torch.cat(y_list, dim=-1)\n",
    "    logits = torch.cat(logits_list, dim=-1)\n",
    "    pred = torch.sigmoid(logits)\n",
    "    if attention:\n",
    "        s_m = torch.cat(s_m_list, dim=0)\n",
    "\n",
    "\n",
    "y = np.array(y)\n",
    "pred = np.array(pred)\n",
    "if attention:\n",
    "    s_m = np.array(s_m)\n",
    "\n",
    "AP = average_precision_score(y, pred)\n",
    "\n",
    "print(f'AP = {AP}')\n",
    "print(f'loss.mean() = {loss.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5303152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention\n",
    "\n",
    "num_freq_bands = len(freq_bands)\n",
    "my_mod = CustomLightningModule(num_freq_bands, dedicated_vgg=dedicated_vgg, eps=eps, train_eps=train_eps, dedicated_GIN=dedicated_GIN, attention=attention, heads=1, d_qk=15, d_v=15)\n",
    "my_mod.load_state_dict(best_model_state)\n",
    "\n",
    "loss_list = []\n",
    "y_list = []\n",
    "logits_list = []\n",
    "s_m_list = []\n",
    "\n",
    "dataset = CustomDataset(val_segments, val_adjs, val_labels, 0, montage)\n",
    "dl = torch.utils.data.DataLoader(dataset, batch_size=val_B, shuffle=False, num_workers=mp.cpu_count()-1,\n",
    "                                 collate_fn=collate_fn, pin_memory=False, drop_last=False)\n",
    "\n",
    "my_mod.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in dl:\n",
    "        # num_nodes_in_examples, segments, y, *sparse_matrices = batch\n",
    "        num_nodes_in_examples, segments, y, *indices = batch\n",
    "        \n",
    "        total_num_nodes = num_nodes_in_examples.sum().item()\n",
    "        sparse_matrices = []\n",
    "        for i in indices:\n",
    "            v = torch.ones((i.shape[1],), dtype=torch.float, device=i.device)\n",
    "            sparse_mat = torch.sparse_coo_tensor(i, v, [total_num_nodes, total_num_nodes])\n",
    "            sparse_matrices.append(sparse_mat)\n",
    "        \n",
    "        \n",
    "        logits, s_m = my_mod(num_nodes_in_examples, segments, sparse_matrices)\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(logits, y)\n",
    "        \n",
    "        loss_list.append(loss)\n",
    "        y_list.append(y)\n",
    "        logits_list.append(logits)\n",
    "        s_m_list.append(s_m)\n",
    "    \n",
    "    loss = torch.stack(loss_list)\n",
    "    y = torch.cat(y_list, dim=-1)\n",
    "    logits = torch.cat(logits_list, dim=-1)\n",
    "    pred = torch.sigmoid(logits)\n",
    "    s_m = torch.cat(s_m_list, dim=0)\n",
    "\n",
    "\n",
    "y = np.array(y)\n",
    "pred = np.array(pred)\n",
    "s_m = np.array(s_m).squeeze()\n",
    "\n",
    "AP = average_precision_score(y, pred)\n",
    "\n",
    "print(f'AP = {AP}')\n",
    "print(f'loss.mean() = {loss.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s_m.shape)\n",
    "print(s_m.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe22eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_m_argmax = s_m.argmax(axis=1)\n",
    "s_m_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f3abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(s_m_argmax, return_counts=True)\n",
    "\n",
    "unique = [freq_bands[i] for i in unique]\n",
    "\n",
    "print(f'unique = {unique}')\n",
    "print(f'couts = {counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_band_idx = 3\n",
    "\n",
    "mask = (s_m_argmax == freq_band_idx)\n",
    "u, c = np.unique(y[mask], return_counts=True)\n",
    "print(f'u, c = ({u}, {c})')\n",
    "diff = np.abs(y[mask] - pred[mask])\n",
    "print(f'mean difference: {diff.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2bd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891efe78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1ce5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
