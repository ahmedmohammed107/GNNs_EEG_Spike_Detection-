{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a4b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reasons, file descriptors (FDs) do not get released.\n",
    "# This is a work around which increases the allowed limit.\n",
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (2048, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22b40d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmedmohammed/opt/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d920b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "train_B = 16\n",
    "eval_B = 1\n",
    "\n",
    "p_dropout = 0.2\n",
    "no_temporal_kernels = 15\n",
    "no_spatial_kernels = 2\n",
    "\n",
    "SCALE = True\n",
    "\n",
    "order = [\n",
    "    'FP1', 'F7', 'T3', 'T5', 'O1',\n",
    "    'F3', 'C3', 'P3',\n",
    "    'FZ', 'CZ', 'PZ',\n",
    "    'FP2', 'F8', 'T4', 'T6', 'O2',\n",
    "    'F4', 'C4', 'P4'\n",
    "]\n",
    "\n",
    "g1 = ['PAT31', 'MC', 'FEsg', 'DHut', 'NKra', 'PAT2']\n",
    "g2 = ['RC', 'MBra', 'ESow', 'PAT1', 'EG', 'FigSa', 'PAT28']\n",
    "g3 = ['PAT47', 'RA', 'PAT51', 'MPi', 'GNA', 'LM', 'DG']\n",
    "g4 = ['PAT33', 'PB', 'PAT22', 'MAXJ', 'PAT19', 'LP', 'HeMod', 'PAT50', 'PJuly']\n",
    "g5 = ['PAT48', 'KS', 'PAT3', 'PAT8', 'LRio', 'HB', 'ALo', 'JAlv', 'PAT25', 'AR']\n",
    "\n",
    "data_folder = 'BH average 100-sps (0.75-38 Hz)'\n",
    "files_names = os.listdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02142b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_group = 'g2'\n",
    "\n",
    "if eval_group == 'g1':\n",
    "    train_patients = g2 + g3 + g4 + g5\n",
    "    eval_patients = g1\n",
    "elif eval_group == 'g2':\n",
    "    train_patients = g1 + g3 + g4 + g5\n",
    "    eval_patients = g2\n",
    "elif eval_group == 'g3':\n",
    "    train_patients = g1 + g2 + g4 + g5\n",
    "    eval_patients = g3\n",
    "elif eval_group == 'g4':\n",
    "    train_patients = g1 + g2 + g3 + g5\n",
    "    eval_patients = g4\n",
    "elif eval_group == 'g5':\n",
    "    train_patients = g1 + g2 + g3 + g4\n",
    "    eval_patients = g5\n",
    "else:\n",
    "    raise NameError('Unknown Eval Group !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d84ebf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_patient_data(patient_name):\n",
    "    \n",
    "    patient_segments = []\n",
    "    patient_labels = []\n",
    "    \n",
    "    regex = re.compile(f'{patient_name}\\D[0-9.a-z_A-Z]*')\n",
    "    \n",
    "    for file_name in files_names:\n",
    "        if regex.match(file_name):\n",
    "            segment = torch.tensor( loadmat(os.path.join(data_folder, file_name))['segment'] ).float()\n",
    "            if 'sp' in file_name:\n",
    "                label = torch.tensor(1.0, dtype=torch.float)\n",
    "            elif 'ns' in file_name:\n",
    "                label = torch.tensor(0.0, dtype=torch.float)\n",
    "            else:\n",
    "                raise NameError('Unknown label!')\n",
    "            \n",
    "            patient_segments.append(segment)\n",
    "            patient_labels.append(label)\n",
    "    \n",
    "    return patient_segments, patient_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segments = []\n",
    "train_labels = []\n",
    "\n",
    "for p in train_patients:\n",
    "    segments, labels = prep_patient_data(p)\n",
    "    train_segments += segments\n",
    "    train_labels += labels\n",
    "\n",
    "\n",
    "\n",
    "eval_segments = []\n",
    "eval_labels = []\n",
    "\n",
    "for p in eval_patients:\n",
    "    segments, labels = prep_patient_data(p)\n",
    "    eval_segments += segments\n",
    "    eval_labels += labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e1aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_IQR_func(group_segments):\n",
    "    numbers = []\n",
    "    for segment in group_segments:\n",
    "        for row in range(segment.shape[0]):\n",
    "            for col in range(segment.shape[1]):\n",
    "                numbers.append(segment[row, col].item())\n",
    "    \n",
    "    quantiles = torch.tensor(numbers).quantile( torch.tensor([0.25, 0.5, 0.75]) )\n",
    "    median = quantiles[1].item()\n",
    "    IQR = quantiles[2].item() - quantiles[0].item()\n",
    "    \n",
    "    return median, IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb30c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_func(group_segments, median, IQR):\n",
    "    # Scales the group_segments list inplace\n",
    "    for idx in range(len(group_segments)):\n",
    "        group_segments[idx] = ((group_segments[idx] - median) / IQR)\n",
    "    \n",
    "    return group_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCALE:\n",
    "    median, IQR = median_IQR_func(train_segments)\n",
    "    train_segments = scaler_func(train_segments, median, IQR)\n",
    "    eval_segments = scaler_func(eval_segments, median, IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b02026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, segments, labels, flip_prob, order):\n",
    "        self.segments = segments\n",
    "        self.labels = labels\n",
    "        self.flip_prob = flip_prob\n",
    "        \n",
    "        if flip_prob > 0:\n",
    "            self.idx_swaps = self.idx_swap_func(order)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def idx_swap_func(order):\n",
    "        dic = {electrode: idx for idx, electrode in enumerate(order)}\n",
    "        \n",
    "        label_swaps = [('FP1', 'FP2'), ('F7', 'F8'), ('F3', 'F4'), ('C3', 'C4'), ('P3', 'P4'), ('T3', 'T4'), ('T5', 'T6'), ('O1', 'O2')]\n",
    "        return [(dic[e_left], dic[e_right]) for e_left, e_right in label_swaps]\n",
    "    \n",
    "    \n",
    "    def flip_lr(self, segment):\n",
    "        # flip left and right\n",
    "        for e_left, e_right in self.idx_swaps:\n",
    "            cloned_channel = torch.clone(segment[e_left])\n",
    "            segment[e_left] = segment[e_right]\n",
    "            segment[e_right] = cloned_channel\n",
    "        \n",
    "        return segment\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if random.random() < self.flip_prob:\n",
    "            seg = self.flip_lr( torch.clone(self.segments[index]) )\n",
    "        else:\n",
    "            seg = self.segments[index]\n",
    "        \n",
    "        return seg, self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_segments, train_labels, 0.5, order)\n",
    "eval_dataset = CustomDataset(eval_segments, eval_labels, 0, order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83864e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del files_names\n",
    "del train_segments, train_labels, train_patients\n",
    "del eval_segments, eval_labels, eval_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d48f2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatioTemporalCNN(torch.nn.Module):\n",
    "    def __init__(self, no_temporal_kernels=15, no_spatial_kernels=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # (B, 1, 300, 19) ====> (B, 16, 251, 19)\n",
    "        self.temporal_cnn = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=no_temporal_kernels, kernel_size=(50, 1)\n",
    "        )\n",
    "        \n",
    "        self.module_list = torch.nn.ModuleList([\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=no_spatial_kernels, kernel_size=(1,19)) \\\n",
    "            for c in range(no_temporal_kernels)\n",
    "        ])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, 300, 19)\n",
    "        \n",
    "        x = self.temporal_cnn(x)\n",
    "        \n",
    "        B, no_temporal_kernels, N, E = x.shape         # N: 251, E: no_electrodes (19)\n",
    "        \n",
    "        no_spatial_kernels = self.module_list[0].out_channels\n",
    "        \n",
    "        y = torch.empty(\n",
    "            (B, no_spatial_kernels, N, no_temporal_kernels),\n",
    "            device=x.device\n",
    "        )\n",
    "        for c in range(no_temporal_kernels):\n",
    "            input_tensor = x[:, c:c+1, :, :]                      # (B, 1, N, E)\n",
    "            output_tensor = self.module_list[c](input_tensor)     # (B, no_spatial_kernels, N, 1)\n",
    "            y[:, :, :, c:c+1] = output_tensor.clone()\n",
    "        \n",
    "        y.transpose_(-2, -3)   # (B, N, no_spatial_kernels, no_temporal_kernels)\n",
    "        y.transpose_(-1, -2)   # (B, N, no_temporal_kernels, no_spatial_kernels)\n",
    "        \n",
    "        return y.flatten(-2, -1)        # (B, N, no_temporal_kernels * no_spatial_kernels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3def2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMultiHeadSelfAttention(torch.nn.Module):\n",
    "    def __init__(self, no_input_features, H, d_qk, d_v, dim, mask=None, bias_att=False, bias_out=False):\n",
    "        super().__init__()\n",
    "        self.H = H\n",
    "        self.d_qk = d_qk\n",
    "        self.d_v = d_v\n",
    "        \n",
    "        # dim: dimension across which to attend\n",
    "        if dim not in {-1, -2}:\n",
    "            raise NameError('Error: Enforce your attention dimension to either -1 or -2 !')\n",
    "        self.dim = dim\n",
    "        \n",
    "        # Most probably mask will be a string (\"all_but_self\", \"no_future\", or \"no_present_no_future\").\n",
    "        # But it can be an actual mask though of shape (E, E) or (T, T)\n",
    "        self.mask = mask\n",
    "        \n",
    "        self.att_lin = torch.nn.Linear(in_features=no_input_features, out_features=(2 * H * d_qk) + (H * d_v), bias=bias_att)\n",
    "        self.out_lin = torch.nn.Linear(in_features=H*d_v, out_features=no_input_features, bias=bias_out)\n",
    "        \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def qkv_func(q, k, v, mask=None):\n",
    "        # no_electrodes: E or T\n",
    "        # q: (B, H, E or T, d_qk)\n",
    "        # k: (B, H, E or T, d_qk)\n",
    "        # v: (B, H, E or T, d_v)\n",
    "        \n",
    "        B, H, E, d_qk = q.shape\n",
    "        d_v = v.shape[-1]\n",
    "        \n",
    "        # logits: (B, H, E or T, E or T)\n",
    "        logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "        \n",
    "        if mask is not None:\n",
    "            if isinstance(mask, str):\n",
    "                if mask == 'all_but_self':\n",
    "                    mask = ( torch.eye(E, device=logits.device) == 0 )\n",
    "                elif mask == 'no_future':\n",
    "                    mask = ( torch.ones((E, E), device=logits.device).tril() == 1 )\n",
    "                elif mask == 'no_present_no_future':\n",
    "                    mask = ( torch.ones((E, E), device=logits.device).tril(-1) == 1 )\n",
    "                else:\n",
    "                    raise NameError(f'Error: Available mask strings are (\"all_but_self\", \"no_future\", \"no_present_no_future\") but \"{mask}\" was given!')\n",
    "            \n",
    "            # mask: (E, E) or (T, T)\n",
    "            # BUT, mask shape MUST be (B, H, E, E) or (B, H, T, T)\n",
    "            mask = mask.expand(B, H, E, E)\n",
    "            logits[mask == False] = -9e15\n",
    "        \n",
    "        s_m = logits.softmax(dim=-1)     # s_m: (B, H, E, E) or (B, H, T, T)\n",
    "        \n",
    "        # (B, H, E, E) * (B, H, E, d_v) = (B, H, E, d_v) ===permute===> (B, E, H, d_v) ===reshape===> (B, E, H * d_v)\n",
    "        # or\n",
    "        # (B, H, T, T) * (B, H, T, d_v) = (B, H, T, d_v) ===transpose===> (B, T, H, d_v) ===reshape===> (B, T, H * d_v)\n",
    "        return torch.matmul(s_m, v).transpose(-2,-3).reshape((B, E, H * d_v))\n",
    "    \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        if self.dim == -1:\n",
    "            # x: (B, C=no_input_features, T or E)\n",
    "            x.transpose_(-1, -2)\n",
    "        \n",
    "        # x: (B, T or E, C=no_input_features)\n",
    "        B, T, no_input_features = x.shape\n",
    "        \n",
    "        # (B, T or E, C=no_input_features) ====self.att_lin====> ( B, T or E, (H * d_qk) + (H * d_qk) + (H * d_v) )\n",
    "        q, k, v = self.att_lin(x).split(split_size=[self.H * self.d_qk, self.H * self.d_qk, self.H * self.d_v], dim=-1)\n",
    "        \n",
    "        q = q.reshape((B, T, self.H, self.d_qk)).transpose(-2, -3)     # q: (B, self.H, T or E, self.d_qk)\n",
    "        k = k.reshape((B, T, self.H, self.d_qk)).transpose(-2, -3)     # k: (B, self.H, T or E, self.d_qk)\n",
    "        v = v.reshape((B, T, self.H, self.d_v)).transpose(-2, -3)      # v: (B, self.H, T or E, self.d_v)\n",
    "        \n",
    "        # priority in the mask is the one used with the forward function\n",
    "        if mask is None:\n",
    "            mask = self.mask\n",
    "        \n",
    "        y = self.out_lin(self.qkv_func(q, k, v, mask=mask))           # (B, T or E, C=no_input_features)\n",
    "        \n",
    "        if self.dim == -1:\n",
    "            x.transpose_(-1, -2)                                       # (B, C=no_input_features, T or E)\n",
    "            y.transpose_(-1, -2)                                       # (B, C=no_input_features, T or E)\n",
    "        \n",
    "        # overall, x preserves its inputted shape & y has the same shape as the inputted x\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f834ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(torch.nn.Module):\n",
    "    def __init__(self, kernel_size, no_input_features, no_output_features, H, d_qk, d_v, dim, mask=None, bias_att=False, bias_out=False, p_dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Most probably mask will be a string (\"all_but_self\", \"no_future\", or \"no_present_no_future\").\n",
    "        # But it can be an actual mask though of shape (E, E) or (T, T)\n",
    "        self.mask = mask\n",
    "        \n",
    "        # Regardless of the provided dim (dimension across which to attend),\n",
    "        # permute the i/p tensor in the forward method to make that dim (T or E) -2\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.att = MaskedMultiHeadSelfAttention(no_input_features, H, d_qk, d_v, -2, mask=mask, bias_att=bias_att, bias_out=bias_out)\n",
    "        self.batch_norm_att = torch.nn.BatchNorm1d(no_input_features)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p_dropout)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(no_input_features, no_output_features)\n",
    "        self.batch_norm_lin = torch.nn.BatchNorm1d(no_input_features)\n",
    "        \n",
    "        self.maxpool = torch.nn.MaxPool1d(kernel_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        if self.dim == -1:\n",
    "            # x: (B, C=no_input_features, T or E)\n",
    "            x.transpose_(-1,-2)\n",
    "        \n",
    "        # x: (B, T or E, no_input_features)\n",
    "        \n",
    "        if mask is None:\n",
    "            mask = self.mask\n",
    "        \n",
    "        y = self.att(x, mask)          # (B, T or E, no_input_features)\n",
    "        y.transpose_(-1, -2)           # (B, no_input_features, T or E)\n",
    "        y = self.batch_norm_att(y)     # (B, no_input_features, T or E)\n",
    "        y.transpose_(-1, -2)           # (B, T or E, no_input_features)\n",
    "        y = self.dropout(y)            # (B, T or E, no_input_features)\n",
    "        \n",
    "        x = x + y\n",
    "        \n",
    "        # x: (B, T or E, no_input_features)\n",
    "        \n",
    "        y = self.lin(x)                # (B, T or E, no_output_features)\n",
    "        y.transpose_(-1, -2)           # (B, no_output_features, T or E)\n",
    "        y = self.batch_norm_lin(y)     # (B, no_output_features, T or E)\n",
    "        y.transpose_(-1, -2)           # (B, T or E, no_output_features)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout(y)            # (B, T or E, no_output_features)\n",
    "        \n",
    "        # Pad the smaller tensor from x and y with zeros to sum match their sizes.\n",
    "        \n",
    "        B, T, no_input_features = x.shape\n",
    "        no_output_features = y.shape[2]\n",
    "        \n",
    "        z = torch.zeros((B, T, abs(no_output_features - no_input_features)), device=x.device)\n",
    "        \n",
    "        if no_output_features > no_input_features:\n",
    "            x = torch.cat((x, z), dim=-1)\n",
    "        else:\n",
    "            y = torch.cat((y, z), dim=-1)\n",
    "        \n",
    "        # max_no_features = max(no_output_features, no_input_features)\n",
    "        \n",
    "        x = x + y                   # (B, T, max_no_features)\n",
    "        \n",
    "        x.transpose_(-1, -2)     # (B, max_no_features, T)\n",
    "        # The last dimension gets reduced by the maxpool layer (T ===> T')\n",
    "        x = self.maxpool(x)      # (B, max_no_features, T')\n",
    "        x.transpose_(-1, -2)     # (B, T', max_no_features)\n",
    "        \n",
    "        if self.dim == -1:\n",
    "            x.transpose_(-1, -2)     # (B, max_no_features, T')\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a6f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineWarmupScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, warmup, max_num_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_num_iters\n",
    "        super().__init__(optimizer)\n",
    "    \n",
    "    \n",
    "    def get_lr(self):\n",
    "        # returns a list of the learning rates\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "    \n",
    "    \n",
    "    def get_lr_factor(self, epoch):\n",
    "        # Optional method that computes lr_factor, NOT learning rate itself.\n",
    "        if epoch <= self.warmup:\n",
    "            slope = (1 - 0) / (self.warmup - 0)\n",
    "            lr_factor = slope * epoch\n",
    "        else:\n",
    "            f = 1 / (2 * (self.max_num_iters - self.warmup))\n",
    "            lr_factor = 0.5 * ( 1 + math.cos( 2 * math.pi * f * (epoch - self.warmup) ) )\n",
    "        \n",
    "        return lr_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd27b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_validation_loss = math.inf\n",
    "best_epoch = 0\n",
    "best_model_state = None\n",
    "AP_at_min_val_loss = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4170aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLightningModule(pl.LightningModule):\n",
    "    def __init__(self, p_dropout, no_temporal_kernels, no_spatial_kernels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.spatiotemporal_cnn = SpatioTemporalCNN(\n",
    "            no_temporal_kernels=no_temporal_kernels,\n",
    "            no_spatial_kernels=no_spatial_kernels\n",
    "        )\n",
    "        \n",
    "        self.batch_norm = torch.nn.BatchNorm1d(\n",
    "            no_temporal_kernels * no_spatial_kernels\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p_dropout)\n",
    "        self.maxpool = torch.nn.MaxPool1d(4)\n",
    "        \n",
    "        \n",
    "        # kernel_size, no_input_features, no_output_features, H, d_qk, d_v, dim, mask=None, bias_att=False, bias_out=False, p_dropout=0.2\n",
    "        self.block_1 = Block(\n",
    "            4, 30, 30, 1, 30, 30, -2, mask=None,\n",
    "            bias_att=False, bias_out=False, p_dropout=p_dropout\n",
    "        )\n",
    "        self.block_2 = Block(\n",
    "            5, 30, 30, 1, 30, 30, -2, mask=None,\n",
    "            bias_att=False, bias_out=False, p_dropout=p_dropout\n",
    "        )\n",
    "        \n",
    "        self.class_lin = torch.nn.Linear(in_features=3*30, out_features=1)\n",
    "        \n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, segment):\n",
    "        # segment: (B, 19, 300)\n",
    "        B = segment.shape[0]\n",
    "        #torch._assert(segment.shape==(B,19,300), f'segment.shape = {segment.shape}')\n",
    "        \n",
    "        segment.transpose_(-1, -2)                    # (B, 300, 19)\n",
    "        segment.unsqueeze_(1)                         # (B, 1, 300, 19)\n",
    "        x = self.spatiotemporal_cnn(segment)          # (B, 251, 32)\n",
    "        \n",
    "        x.transpose_(-1, -2)                          # (B, 32, 251)\n",
    "        x = self.batch_norm(x)                        # (B, 32, 251)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.maxpool(x)                           # (B, 32, 251/4 = 62)\n",
    "        x.transpose_(-1, -2)                          # (B, 62, 32)\n",
    "        \n",
    "        x = self.block_1(x)                           # (B, 62/4 = 15, 32)\n",
    "        x = self.block_2(x)                           # (B, 15/5 = 3, 32)\n",
    "        \n",
    "        x = x.flatten(-2, -1)                         # (B, 90)\n",
    "        \n",
    "        return self.class_lin(x).reshape((B,))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), weight_decay=0)\n",
    "        cosine_scheduler = CosineWarmupScheduler(optimizer=optimizer, warmup=100, max_num_iters=self.trainer.max_epochs)\n",
    "        swa_scheduler = SWALR(optimizer, swa_lr=0.0001, anneal_epochs=100, anneal_strategy='cos')\n",
    "        return [optimizer], [cosine_scheduler, swa_scheduler]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=train_B, shuffle=True, num_workers=0, drop_last=True\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    \n",
    "    \n",
    "    \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        if self.global_rank == 0:\n",
    "            train_loss = torch.stack([dic['loss'] for dic in training_step_outputs]).mean()\n",
    "            print(f'Epoch: {self.current_epoch}')\n",
    "            print(f'Training loss BEFORE optimizer step: {round(train_loss.item(), 5)}')\n",
    "            print('----------------------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            eval_dataset, batch_size=eval_B, shuffle=False, num_workers=0, drop_last=False\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        return {'loss': loss, 'y': y, 'logits': logits}\n",
    "    \n",
    "    \n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        global min_validation_loss, best_epoch, best_model_state, AP_at_min_val_loss\n",
    "        \n",
    "        swa_start_epoch = 1000\n",
    "        \n",
    "        cosine_scheduler, swa_scheduler = self.lr_schedulers()\n",
    "        \n",
    "        if self.current_epoch > 0:\n",
    "            if self.current_epoch < swa_start_epoch:\n",
    "                cosine_scheduler.step()\n",
    "            else:\n",
    "                swa_scheduler.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.global_rank == 0:\n",
    "            \n",
    "            if self.current_epoch > (swa_start_epoch + swa_scheduler.anneal_epochs):\n",
    "                swa_model.update_parameters(self)\n",
    "                \n",
    "            \n",
    "            val_loss = torch.stack([dic['loss'] for dic in validation_step_outputs]).mean()\n",
    "            val_loss = val_loss.item()\n",
    "            print(f'val_loss: {val_loss}')\n",
    "            \n",
    "            y = torch.cat([dic['y'] for dic in validation_step_outputs]).cpu()\n",
    "            logits = torch.cat([dic['logits'] for dic in validation_step_outputs]).cpu()\n",
    "            pred = torch.sigmoid(logits)\n",
    "            \n",
    "            y = np.array(y)\n",
    "            pred = np.array(pred)\n",
    "            \n",
    "            try:\n",
    "                validation_AP = average_precision_score(y, pred)\n",
    "                \n",
    "                if (val_loss < min_validation_loss) and (self.current_epoch > 1):\n",
    "                    min_validation_loss = val_loss\n",
    "                    best_epoch = self.current_epoch\n",
    "                    best_model_state = deepcopy(self.state_dict())\n",
    "                    AP_at_min_val_loss = validation_AP\n",
    "                \n",
    "                \n",
    "                print(f'validation_AP = {round(validation_AP, 5)} ... AP_at_min_val_loss = {round(AP_at_min_val_loss, 5)} @ epoch {best_epoch}')\n",
    "                \n",
    "            except ValueError:\n",
    "                print(f'ValueError @ epoch: {self.current_epoch} ====> y = {y}')\n",
    "            \n",
    "            print('=======================================================================================')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdcbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lightning_module = CustomLightningModule(p_dropout, no_temporal_kernels, no_spatial_kernels)\n",
    "\n",
    "swa_model = AveragedModel(my_lightning_module)\n",
    "\n",
    "trainer = pl.Trainer(gpus=0, enable_checkpointing=False, enable_progress_bar=False, logger=False, max_epochs=500)\n",
    "\n",
    "trainer.fit(my_lightning_module)\n",
    "\n",
    "# Update bn statistics for the swa_model at the end\n",
    "torch.optim.swa_utils.update_bn(my_lightning_module.train_dataloader(), swa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f'models/{eval_group}_satelight_{round(100 * AP_at_min_val_loss, 2)}.pt'\n",
    "torch.save(best_model_state, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58075cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783fb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83379387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedcd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1\n",
    "==\n",
    "maximum validation_AP = 0.86006 @ val_loss: 0.3857518136501312 @ train_loss: 0.02103\n",
    "\n",
    "Epoch: 125\n",
    "Training loss BEFORE optimizer step: 0.08427\n",
    "----------------------------------------------------------------------------\n",
    "val_loss: 0.29432666301727295\n",
    "validation_AP = 0.80855 ... AP_at_min_val_loss = 0.80855 @ epoch 126\n",
    "====================================================================\n",
    "\n",
    "Epoch: 223\n",
    "Training loss BEFORE optimizer step: 0.10962\n",
    "----------------------------------------------------------------------------\n",
    "val_loss: 0.27389994263648987\n",
    "validation_AP = 0.84424 ... AP_at_min_val_loss = 0.84424 @ epoch 224\n",
    "====================================================================\n",
    "\n",
    "\n",
    "\n",
    "g2\n",
    "==\n",
    "maximum validation_AP = 0.89437 @ val_loss: 0.3216995894908905 @ train_loss: 0.03656\n",
    "\n",
    "Epoch: 158\n",
    "Training loss BEFORE optimizer step: 0.04207\n",
    "--------------------------------------------------------------------\n",
    "val_loss: 0.261417955160141\n",
    "validation_AP = 0.88421 ... AP_at_min_val_loss = 0.88421 @ epoch 159\n",
    "====================================================================\n",
    "\n",
    "\n",
    "\n",
    "g3\n",
    "==\n",
    "maximum validation_AP = 0.91116 @ val_loss: 0.28639698028564453 @ train_loss: 0.08264\n",
    "validation_AP = 0.9136 @ val_loss: 0.3856848478317261 @ train_loss: 0.0163\n",
    "maximum validation_AP = 0.91742 @ val_loss: 0.33682939410209656 @ train_loss: 0.0261\n",
    "\n",
    "Epoch: 81\n",
    "Training loss BEFORE optimizer step: 0.10821\n",
    "-------------------------------------------------------------------\n",
    "val_loss: 0.22748209536075592\n",
    "validation_AP = 0.89869 ... AP_at_min_val_loss = 0.89869 @ epoch 82\n",
    "===================================================================\n",
    "\n",
    "Epoch: 108\n",
    "Training loss BEFORE optimizer step: 0.08981\n",
    "----------------------------------------------------------------------------\n",
    "val_loss: 0.23838919401168823\n",
    "validation_AP = 0.90162 ... AP_at_min_val_loss = 0.90162 @ epoch 109\n",
    "====================================================================\n",
    "\n",
    "\n",
    "\n",
    "g4\n",
    "==\n",
    "validation_AP = 0.94751 @ val_loss: 0.2212197333574295 @ train_loss: 0.01003\n",
    "\n",
    "Epoch: 235\n",
    "Training loss BEFORE optimizer step: 0.03781\n",
    "----------------------------------------------------------------------------\n",
    "val_loss: 0.15423248708248138\n",
    "validation_AP = 0.95322 ... AP_at_min_val_loss = 0.95322 @ epoch 236\n",
    "====================================================================\n",
    "\n",
    "\n",
    "\n",
    "g5\n",
    "==\n",
    "Epoch: 184\n",
    "Training loss BEFORE optimizer step: 0.01027\n",
    "---------------------------------------------------------------------\n",
    "val_loss: 0.14156535267829895\n",
    "validation_AP = 0.96198 ... AP_at_min_val_loss = 0.96198 @ epoch 185\n",
    "====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4cb866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2583ba69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d673866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "model = CustomLightningModule(p_dropout, no_temporal_kernels, no_spatial_kernels)\n",
    "\n",
    "#IEDs_names = [item for item in os.listdir(data_folder) if 'sp' in item]\n",
    "NIEDs_names = [item for item in os.listdir(data_folder) if 'ns' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c341b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(patients_names):\n",
    "    group_segments = []\n",
    "    group_labels = []\n",
    "    \n",
    "    for patient_name in patients_names:\n",
    "        patient_segments, patient_labels = prep_patient_data(patient_name)\n",
    "        group_segments += patient_segments\n",
    "        group_labels += patient_labels\n",
    "    \n",
    "    return group_segments, group_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3731c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [item for item in os.listdir('models/') if 'g1_satelight' in item]\n",
    "g1_model_name = max(lis)\n",
    "train_segments, _ = prepare_dataset(g2 + g3 + g4 + g5)\n",
    "g1_median, g1_IQR = median_IQR_func(train_segments)\n",
    "\n",
    "lis = [item for item in os.listdir('models/') if 'g2_satelight' in item]\n",
    "g2_model_name = max(lis)\n",
    "train_segments, _ = prepare_dataset(g1 + g3 + g4 + g5)\n",
    "g2_median, g2_IQR = median_IQR_func(train_segments)\n",
    "\n",
    "\n",
    "lis = [item for item in os.listdir('models/') if 'g3_satelight' in item]\n",
    "g3_model_name = max(lis)\n",
    "train_segments, _ = prepare_dataset(g1 + g2 + g4 + g5)\n",
    "g3_median, g3_IQR = median_IQR_func(train_segments)\n",
    "\n",
    "\n",
    "lis = [item for item in os.listdir('models/') if 'g4_satelight' in item]\n",
    "g4_model_name = max(lis)\n",
    "train_segments, _ = prepare_dataset(g1 + g2 + g3 + g5)\n",
    "g4_median, g4_IQR = median_IQR_func(train_segments)\n",
    "\n",
    "\n",
    "lis = [item for item in os.listdir('models/') if 'g5_satelight' in item]\n",
    "g5_model_name = max(lis)\n",
    "train_segments, _ = prepare_dataset(g1 + g2 + g3 + g4)\n",
    "g5_median, g5_IQR = median_IQR_func(train_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78167813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = pd.Series(index=IEDs_names, dtype='float64')\n",
    "s = pd.Series(index=NIEDs_names, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8a0676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for IED_name in IEDs_names:\n",
    "for NIED_name in NIEDs_names:\n",
    "    #segment = loadmat(os.path.join(data_folder, IED_name))['segment']\n",
    "    segment = loadmat(os.path.join(data_folder, NIED_name))['segment']\n",
    "    segment = torch.tensor(segment).float()\n",
    "    \n",
    "    #patient_name = IED_name[: IED_name.find('_')]\n",
    "    patient_name = NIED_name[: NIED_name.find('_')]\n",
    "    \n",
    "    if patient_name in g1:\n",
    "        segment = (segment - g1_median) / g1_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g1_model_name}'))\n",
    "    elif patient_name in g2:\n",
    "        segment = (segment - g2_median) / g2_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g2_model_name}'))\n",
    "    elif patient_name in g3:\n",
    "        segment = (segment - g3_median) / g3_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g3_model_name}'))\n",
    "    elif patient_name in g4:\n",
    "        segment = (segment - g4_median) / g4_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g4_model_name}'))\n",
    "    elif patient_name in g5:\n",
    "        segment = (segment - g5_median) / g5_IQR\n",
    "        model.load_state_dict(torch.load(f'models/{g5_model_name}'))\n",
    "    else:\n",
    "        raise NameError('Unknown Patient')\n",
    "    \n",
    "    \n",
    "    segment.unsqueeze_(0)\n",
    "    model.eval()\n",
    "    \n",
    "    #s.at[IED_name] = torch.sigmoid(model(segment)).item()\n",
    "    s.at[NIED_name] = torch.sigmoid(model(segment)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d91fcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RC_24_ns.mat      0.000196\n",
       "FEsg_38_ns.mat    0.032728\n",
       "HB_2_ns.mat       0.000244\n",
       "FEsg_26_ns.mat    0.054695\n",
       "FigSa_9_ns.mat    0.013867\n",
       "                    ...   \n",
       "LM_3_ns.mat       0.035856\n",
       "RC_6_ns.mat       0.002633\n",
       "FEsg_19_ns.mat    0.096821\n",
       "NKra_10_ns.mat    0.082357\n",
       "PAT48_ns_6.mat    0.001178\n",
       "Length: 593, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4970f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.ExcelWriter('IEDs_results.xlsx', mode='a') as writer:\n",
    "with pd.ExcelWriter('NIEDs_results.xlsx', mode='a') as writer:\n",
    "    s.to_excel(writer, sheet_name='satelight', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206619b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
